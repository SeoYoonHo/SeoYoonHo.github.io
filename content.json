{"pages":[],"posts":[{"title":"AWS Lambda를 이용한 Restful API서비스 개발(1)","text":"최근 회사에서 Kafka와 Lambda를 이용한 서비스개발에 착수하게 되었다. 기존에 Lambda를 이용한 api개발 경험이 있었기에 큰 어려움 없이 구상을 할 수 있었지만, 본격적으로 진행하기 전에 lambda와 serverless에 대해 내용을 정리해보고자 한다. AWS Lambda란?AWS 람다는 2014년 11월 AWS re:Invent에서 처음 발표된 AWS에서 제공되는 서버리스 컴퓨팅 서비스이다. Serverless란 별도의 서버 셋업 없이 곧바로 코드를 실행해주는 서비스이다. Serverless라는 단어를 오해해서 실제 서버가 없는것으로 오해하는데 진정한 의미는 개발자가 직접 관리해야하는 서버가 없다는 뜻이다. 다시 말하자면 보이지 않는 곳에서 관리형 서버(추상화된 서버)가 따로 존재하고, 필요에 따라 자동으로 Scale up 되거나 Scale down된다. Lambda 언어AWS에서는 C#, 파워셀, GO, Java, JavaScript, Python, Ruby등을 네이티브하게 지원하고 있다. 각각의 런타임별로 지원시기가 정해져있고, 지원기간이 종료되면 더이상 사용할 수가 없다. 지원 종료시기에 대해서 미리 파악하고 버전 업그레이드를 해주는게 중요하다. 우선 우리가 사용할 런타임은 node js이고 Node.js의 런타임은 지원은 다음과 같다. Lambda 함수트리거람다는 특정 이벤트를 기반으로 요청받은 그 즉시 실행된다. API Gateway나 애플리케이션 로드밸런서가 받은 요청을 기반으로 실행할 수도 있으며, AWS의 다양한 서비스와 연동할 수 있다. 현재 진행중인 프로젝트의 경우 API Gateway와 연동하여 Restful API의 개발과, 카프카와 연동한 개발이 진행될 예정이다. Lambda 과금체계Lambda를 사용하는 이점은 서버를 관리해주지 않아도 된다는점, 그리고 저렴한 비용이 있다. 하지만 상황에 따라 Lambda보다 ec2 인스턴스위에서 서비스를 제공하는게 저렴할 수 있으니, Lambda에 대한 과금체계를 잘 이해하여 선택해야한다. 우선 Lambda는 두가지 요소로 과금한다. 함수 요청 건수 함수 실행 시간 두 요소에서 발생된 금액을(건수요금 + 실행시간요금) 합쳐 과금이 되는 것이다. 예를 들어 프리티어가 포함된 AWS계정으로 미국 동부(버지니아 북부) 리전에서 람다를 수행하는 경우, 함수에 512MB 메모리를 할당하고 한달에 3백만회 실행시 매번 1초간 실행하였다면 과금 체계는 다음과 같다. 컴퓨팅 요금월별 컴퓨팅 요금은 GB-초당 0.00001667USD이고 프리티어에서 400,000GB-초를 제공.총 컴퓨팅(초) = 300만회 * 1초 = 3,000,000초총 컴퓨팅(GB-초) = 3,000,000 / 2 = 1,500,000GB-초(가격테이블 기준, 메모리를 1/2만 사용하였으므로 컴퓨팅 시간을 1/2로 계산해줌) 프리티어 제공 빼줌1,5000,000GB-초 - 400,000GB-초 = 1,100,000GB-초월별 컴퓨팅 요금 = 1,100,000 * 0.00001667USD = 18.34USD; 요청 요금프리티어 기준 1백만회 무상제공 -&gt; 2백만회 과금월별 요청 요금 = 2 * 0.2USD/월 = 0.4USD 총 요금 = 1) + 2) = 18.74USD Lambda VS EC2위에서 보다시피 람다는 순수하게 사용시간,요청건수에 의해 과금을 한다. 그래서 EC2와 비교했을 떄 효율적으로 자원을 사용할 수 있지만, 건수나 시간이 많아질 경우 오히려 더 비싸지는 경우가 발생할 수 있다. 다음은 두가지 시나리오에 따른 EC2와 Lambda의 과금을 비교한 표이다. 애플리케이션이 하루에 5,000회 실행되며, 각 실행이 512MB의 메모리 사이즈로 100ms가 소요된다고 가정한다. 이 때의 Lambda 함수의 비용은 0.16달러가 된다. 같은 요구 사항에 대해 t2.nano EC2 인스턴스를 사용한다면, 비용은 약 월 4.25달러이다.단순한 예시이지만, 이때는 람다 가격이 EC2 가격의 4%에 불과하다는 것을 알 수 있다. 두 번째 시나리오를 예로 들어 보자. 한 달에 500만번 실행되는 1GB Lambda 함수는 평균 200ms가 소요된다. 이때의 비용은 17.67달러이지만, EC2 t3.micro를 사용한다면 비용은 7.62달러밖에 들지 않을 것다. 따라서 이 경우, 메모리/요청/실행시간이 많이 요구되기 때문에 오히려 EC2가 람다보다 저렴한 솔루션이 될 수 있다. 마치며오늘은 AWS의 Lambda에 대해 알아보는 시간을 가졌다. 다음 포스팅에서는 해당 람다를 개발하기 위한 환경으로써 Serverless Framework에 대해 알아보도록 하겠다. 출처: https://www.44bits.io/ko/keyword/aws-lambda https://sa-na.tistory.com/entry/AWS-%EB%B9%84%EC%9A%A9%EC%A4%84%EC%9D%B4%EA%B8%B0-7-Serverless-%EC%86%94%EB%A3%A8%EC%85%98-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-AWS-Lambda https://blog.naver.com/PostView.naver?blogId=sehyunfa&amp;logNo=222343068462&amp;redirect=Dlog&amp;widgetTypeCall=true&amp;directAccess=false","link":"/2022/07/07/AWS-Lambda%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-Restful-API%EC%84%9C%EB%B9%84%EC%8A%A4-%EA%B0%9C%EB%B0%9C(1)/"},{"title":"DB 트랜잭션","text":"트랜잭션이란?트랜잭션은 하나의 작업을 수행하기 위해 필요한 데이터베이스의 연산들을 모아놓은 것으로, 데이터베이서에서 논리적인 작업의 단위이며 장애가 발생했을 때 데이터를 복구하는 작업의 단위이다. 현업에서 쓰이는 개념으로 쉽게 설명하면 트랜잭션 단위로 데이터의 커밋과 롤백이 이루어진다. 커밋(Commit) : 모든 부분작업이 정상적으로 완료되면 이 변경사항을 한꺼번에 DB에 반영한다. 롤백(Rollback) : 부분 작업이 실패하면 트랜잭션 실행 전으로 되돌린다.이때, 모든 연산을 취소하지 않고 정해진 부분까지만 되돌리고 싶을 때 사용하는 것이 savepoint이다. 트랜잭션의 특징(ACID)트랜잭션이 성공적으로 처리되어 데이터베이스의 무결성과 일관성을 보장하기 위해 4가지 특징을 만족해야한다. 4가지 특징은 다음과 같다. 원자성(Atomicity) 일관성(Consistency) 격리성(Isolation) 지속성(Durability) 각각의 특징에 대하여 자세하게 알아보자 원자성 (Atomicity) 트랜잭션을 구성하는 연산들은 모두 정상적으로 실행되거나 하나도 실행되지 않아야 한다는 all or nothing 방식이다. 트랜잭션의 연산은 데이터베이스에 모두 반영되든지 아니면 전혀 반영되지 않아야한다. 트랜잭션 내의 모든 명령은 반드시 완벽하게 수행되어야 하며, 모두가 완벽히 수행되지 않고 어느 하나라도 오류가 발생한다면 트랜잭션 전부가 취소되어야 한다. 일관성 (Consistency) 트랜잭션이 실행을 성공적으로 완료하면 언제나 일관성 있는 데이터베이스 상태로 유지하는 것을 의미한다. 예를 들어 무결성 제약이 모든 계좌는 잔고가 있어야 한다면 이를 위반하는 트랜잭션은 중단된다. 독립성 (Isolation) 트랜잭션 수행시 다른 트랜잭션의 연산 작업이 끼어들지 못하도록 보장하는 것을 의미한다. 수행중인 트랜잭션은 완전히 완료될 때까지 다른 트랜잭션에서 수행 결과를 참조할 수 없다. 예를 들어 은행 관리자는 이체 작업을 하는 도중 쿼리를 실행하더라도 특정 계좌간 이체하는 양 쪽을 볼 수없다. 성능 관련 이유로 인해 이 특성은 가장 유연성이 있는 제약조건이다. 지속성 (Durability) 성공적으로 수행된 트랜잭션은 영구적으로 반영되어야 함을 의미한다. 트랜잭션 연산보통 DB를 사용 할 때, 쿼리를 날리는 시점에 데이터베이스에 반영된다고 생각한다. 하지만 데이터베이스에 반영되는 시점은 트랜잭션 연산이 성공적으로 완료되는 시점에 실제 데이터베이스에 반영이 된다. 트랜잭션 연산에는 크게 두가지 과정이 있다. commit 연산 트랜잭션이 성공적으로 수행되었음을 선언(작업 완료) commit 연산이 실행 된 후에야 트랜잭션의 수행결과가 데이터베이스에 반영되어 일관된 상태를 지속적으로 유지. commit 연산의 실행을 통해 트랜잭션의 수행이 성공적으로 완료되었음을 선언하고 결과를 최종 데이터베이스에 반영. rollback 연산 트랜잭션이 수행을 실패했음을 선언(작업 취소) rollback 연산이 실행되면 트랜잭션이 지금까지 실행한 연산의 결과가 취소되고 트랜잭션이 수행되기 전의 상태로 돌아간다. 트랜잭션 수행 도중 일부 연산이 처리되지 못한 상황에서는 rollback 연산을 실행하여 트랜잭션의 수행이 실패했음을 선언하고, 모순되지 않도록 데이터베이스를 트랜잭션 수행 전의 일관된 상태로 되돌려야한다. 트랜잭션 상태트랜잭션은 위와 같은 연산을 수행할 떄 크게 5가지의 상태가 존재하고 상태 처리 과정은 아래 그림과 같다 활성(Active) : 트랜잭션이 정상적으로 실행중인 상태실패(Failed) : 트랜잭션 실행에 오류가 발생하여 중단된 상태철회(Aborted) : 트랜잭션이 비정상적으로 종료되어 Rollback 연산을 수행한 상태부분 완료(Partially Committed) : 트랜잭션의 마지막 연산까지 실행했지만, Commit 연산이 실행되기 직전의 상태완료(Committed) : 트랜잭션이 성공적으로 종료되어 Commit 연산을 실행한 후의 상태","link":"/2022/03/26/DB-%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98/"},{"title":"JDBC 타임아웃","text":"시스템을 운영하는 입장에서 개발을 진행한다면 다양한 상황들을 가정하게 된다. 프로그램이 갑작스럽게 죽었을 경우, 서버가 다운됐을 경우, DDos 공격을 당하게 되었을 경우등이 가정되는 상황들이다. 이러한 이벤트에서도 시스템은 피해를 최소화할 수 있어야 한다. 이와 관련하여 과거 진행되었던 개발건 중 JDBC 타임아웃 설정에 관한 좋은 경험이 있어 공유하고 설명하고자 한다. DB서버의 먹통2020년 실시간으로 들어오는 다량의 데이터들을 DB에 적재하는 프로그램 개발을 맡게 되었다. Kinesis로부터 읽어들인 데이터를 DB에 적재하면 되는 단순할 수 있는 개발건이었지만, 기존에 운영중인 시스템의 구조를 바꾸는 일이라 영향도가 꽤나 큰 건이었다. 기능 개발은 단기간에 끝났지만 성능테스트와 발생할 수 있는 다양한 상황에 대응하는 기능들을 추가하는데 공수가 더 들어가게 되었다. 다양한 상황중 하나를 소개하고 그 대응책으로 고른 내용을 공유하고자 한다. 그 상황은 다음과 같다. DB서버가 장애가 날 경우 프로그램은 어떻게 동작해야하는가? 의식의 흐름대로 개발을 한다면 다음과 같은 프로세스대로 동작하면 된다. DB가 죽을 경우 Kinesis로부터 Read하는 행위를 정지한다. DB Reconnect를 주기적으로 실시한다. DB Connect가 성공하는 순간 Kinesis로부터 Read행위를 재개한다. 이 프로세스에서 가장 핵심이 되는 문제는 1번, DB의 비정상적인 종료를 캐치하는 것이었다.DB Transaction 프레임워크로 Mybatis를 설정하였기에 statement 타임아웃 설정을 해주었고, 나머지 2,3번 프로세스대로 개발을 진행하였다. 개발 완료 후 DB를 중지시키는 테스트를 진행하였을 때 프로그램은 DB의 비정상적인 종료를 캐치하지 못하였다. DB의 응답을 기다리면서 Kinesis로부터 계속 데이터를 읽어들였고, 차오르는 메모리로 인해 oom이 발생하며 프로그램은 종료되었다.아래는 mybatis에서 설정해준 statement timeout 설정파일이다. …&lt;setting name=”defaultStatementTimeout” value=”25000”/&gt;… 무엇이 문제였을까? mybatis의 타임아웃 설정이 잘못되었던건가? 이를 이해하기 위해선 JDBC의 타임아웃 과정을 보면 이해할 수 있다.앞으로 나올 내용은 Naver O2에 포스팅 된 아주 좋은내용의 블로그를 참고하였다(https://d2.naver.com/helloworld/1321) JDBC typeJDBC는 자바 프로그램이 DBMS에 일관된 방식으로 접근할 수 있도록 API를 제공하는 자바 클래스들의 모임이다. 즉 데이터베이스에 연결 및 작업을 하기 위한 JAVA의 표준 인터페이스이다.JDBC의 유형은 총 4가지가 있는데 현재 재직중인 회사와 운영중인 시스템에선 주로 Type 4를 사용하고 있으므로 이에 대해서 다룬다.(추후에 JDBC에 대해서도 자세하게 다루도록 하겠다.)Type 4는 순수 자바로 이루어져 있으며 Java Socket으로 DB에 직접 교신하는 방식이다. 때문에 Socket Timeout값을 제대로 설정하지 않았을 경우 DB의 문제를 늦게 감지하고 장애로 이어질 수 있다. 위에서 설명한 상황이 바로 이런 상황에 해당된다. DBMS 통신 타임아웃 계층 위의 그림은 WAS와 DBMS의 통신시 타임아웃 계층을 단순화한 것이다. 여기서 Instance를 기본 Java Application으로 대체해도 문제가 없다. 그림에서 보이듯 상위레벨의 타임아웃은 하위레벨의 타임아웃에 의존성을 가지고 있다. Socket Timeout이 정상적으로 동작하지 않으면, 그보다 상위인 Statment Timeout과 Transaction Timeout도 정상적으로 동작하지 않는다. JDBC Socket Timeout의 default값은 OS의 Socket timeout에 영향을 받는다. 별도의 설정이 없을 경우 OS의 Default Socket Timeout값이 적용된다. 즉, 위의 상황에서 30분이 지난다면 Exception이 발생되었을 것이다. 하지만 실시간 프로그램에서 30분은 너무나 긴 시간이고 별도의 시간 설정이 필요해 보인다. 이제부터 각 타임아웃의 의미와 Mybatis에서 Socket Timeout 설정하는 방법에 대해 다뤄보자 Transaction TimeoutTransaction Timeout은 프레임워크나 애플리케이션 레벨에서 유효한 타임아웃이다. 간단히 말하면 전체 Statement를 수행하는데 걸리는 시간의 Timeout이라고 할 수 있다. 즉 StatementTimeout * N(Statement 수행수) 정도로 생각해볼 수 있다. Mybatis의 경우 Trasaction Timeout설정은 존재하지 않고 Statement Timeout설정만 존재한다. Statement TimeoutStatement 하나가 얼마나 오래 수행되어도 괜찮은지에 대한 한계값이다. Mybatis의 설정이 위의 예제에서 보여준 방법을 이용하면 된다. Socket Timeout위에서도 말했듯이 Type 4는 Socket을 이용한 DB통신 방식을 이용하고, 이는 DBMS가 Connection Timeout을 처리하지 않음을 의미한다. 즉, 애플리케이션과 DBMS 사이의 장애를 감지할 수 있는 방법은 Socket Timeout값을 설정하는 방법밖에 없다. 이를 간과하였기에 우리 시스템에서는 DB장애를 감지할 수 없었던 것이다. 단, Socket Timeout 값을 Statment의 수행시간을 제한하기 위해 사용하는것은 바람직하지 않으므로, Statement Timeout 값보다는 큰 값을 사용하기를 권장한다. Socket Timeout에는 두가지 옵션이 있고, 드라이버별로 설정방법이 다르다. Socket Connect 시 타임아웃(connectTimeout): Socket.connect(SocketAddress endpoint, int timeout) 메서드를 위한 제한 시간 Socket Read/Write의 타임아웃(socketTimeout): Socket.setSoTimeout(int timeout) 메서드를 위한 제한 시간 드라이버별 설정방법을 여기서 모두 다루지는 않고 Oracle의 경우 Mybatis에서 어떤식으로 설정해줬는지 내용을 공유하려 한다. …&lt;property name=”driver.oracle.jdbc.ReadTimeout” value=”10000”/&gt;&lt;property name=”driver.oracle.net.CONNECT_TIMEOUT” value=”10000”/&gt;… 위의 두 내용이 내가 Mybatis에 설정해준 Socket Timeout 값이다. 끝으로해당 내용을 공부하고 운영환경에 적용하면서 이 설정이 실제로 쓰일까에 대한 고민이 많이 있었다. 하지만 프로그램 반영 후 알 수없는 이유로 DB에 로그파일이 쌓이기 시작하며 스토리지가 모두 소비되었고, DB 서버가 죽는 상황이 실제로 발생하게 되었다. 해당 장애상황에서 대비되었던 설정으로 인해 모든 데이터를 유실 없이 복구할 수 있었다. 역시 운영환경에서 생각할 수 있는 모든 변수는 대비하는게 맞다는 경험을 한번 더 쌓게 되는 계기가 되었다.","link":"/2022/04/06/JDBC-%ED%83%80%EC%9E%84%EC%95%84%EC%9B%83/"},{"title":"Pojo란?","text":"Spring은 POJO 기반의 프레임워크라는 말을 들어보았을 것이다. 여기서 POJO의 의미는 무엇일까? POJO는 Plain Old Java Object의 약자로 말 그대로 해석을 하면 오래된 방식의 자바 오브젝트라는 말이다. 뜻이 애매하고 와닿지도 않는다. 이런 애매모호함은 다양한 해석을 만들었고, 포스팅마다 설명이 다르다. 결국 정확한 어원과 의미를 알아야겠다는 생각을 가지게 되었고, 다양한 자료들을 조사하기 시작하였다. POJO를 정확하게 이해하기 위해서는 단어 등장의 배경부터 알아야한다. EJB의 등장현재에 와서는 상상이 가지 않겠지만 원래 자바의 초점은 클라이언트 GUI를 만다는데 맞춰줘 있었다. 그러다가 곧 서버 시장에서의 가능성에도 주목받기 시작하였으며, 서버개발에 필요한 기능을 모아서 J2EE(현재의 JAVA EE)라는 표준을 만들게 되었다. 하지만 J2EE의 Servlet, JSP 레벨의 최소한의 서버 프로그래밍 인터페이스만 가지고는 복잡한 엔터프라이즈 애플리케이션을 제작하는데에는 부담이 있었다. 기업 업무처리의 IT 시스템에 대한 의존도가 높아지면서 시스템이 다뤄야 하는 비즈니스 로직은 점점 복잡해졌고, 개발자들이 비즈니스 로직과 더불어 다양한 상세기술의 복작함을 다룬다는 것은 쉬운일이 아니었다. 결국 많은 사용자의 처리 요구를 빠르게 안정적이면서 확장 가능한 형태로 유지하기 위해 필요한 로우레벨의 기술적인(트랜잭션 처리, 상태관리, 멀티쓰레딩, 리소스풀링, 보안 등) 처리가 필요했다. 이러한 문제를 다루기 위해 EJB가 등장하였고, EJB의 모토는 ‘개발자는 로우레벨의 기술들에 관심을 가질 필요도 없다’ 였다. EJB의 한계이렇게 등장한 EJB는 당시 개발자들의 주목을 받으며 널리 쓰이게 되었다. 하지만 시간이 지남에 따라 몇 가지 심각한 문제들로 인해 비판을 받게 되었다. EJB 컴포넌트는 컨테이너 밖에서는 정상적으로 동작할 수 없으므로 개발자들은 끝도 없이 반족되는 수정-빌드-배포-테스트의 과정으로 시간을 낭비해야한다. 가장 최악의 문제점은 EJB 스펙을 따르는 비즈니스 오브젝트들은 객체지향적인 특징과 장점을 포기해야했다는 것이다. EJB 빈은 상속과 다형성등의 혜택을 제대로 누릴 수 없었다. POJO 개념의 등장결국 EJB는 낮은 생산성과 느린 성능, 불필요한 기술적인 복잡도등으로 자바의 엔터프라이즈 개발에 대한 불신을 가중시켰고, 마틴 파울러는 EJB와 같은 잘못된 설계된 과도한 기술을 피하고, 객체지향 원리에 따라 만들어진 자바 언어의 기본에 충실하게 비즈니스 로직을 구현하는 일명 POJO 방식으로 돌아서야 한다고 지적했다. POJO방식의 개발은 EJB가 잃어버린 소중한 가치인 객체지향적인 설계와 자동화된 테스트의 편의성, 개발생산성 등을 회복시켜 줄 수 있는 길이기 때문이다. 결국 POJO를 정리하자면 특정 규약에 종속되지 않는다.(Java 언어와 꼭 필요한 API 외에 종속되지 않는다.) 특정 환경에 종속되지 않는다. 객체지향원리에 충실해야 한다. POJO를 사용하는 이유 코드의 간결함(비즈니스 로직과 특정환경/low 레벨 종속적인 코드를 분리하므로 단순하다.) 자동화 테스트에 유리 객체지향적 설계의 자유로운 사용 POJO 개념의 오해많은 자료를 조사하다보니 POJO객체를 기본자료형과 Getter/Setter메소드로만 이루어진 클래스로 정의하는것을 보았다. 하지만 위에서 살펴본 것과 같이 POJO의 등장배경과 의미를 살펴보면, 특정 규약/환경에 종속되지 않은 일반적인 클래스들을 지칭하는 단어임을 알 수 있다. 즉, 엄밀히 말하면 Getter/Setter 메소드로 이루어진 클래스는 POJO에 포함된 개념으로 볼 수 있다. 마치며오늘은 POJO의 등장배경에 대해 알아보았다. 이 포스팅을 정리하며 EJB부터 Spring까지 Java 서버개발의 역사에 대해 전반적으로 알 수 있었다. 사실 EJB에 대해서 정확하게 알 수는 없지만 Spring, Pojo의 등장 배경에 대해 좀 더 잘 이해할 수 있는 시간이어서 의미있는 시간이었다. 이전 포스팅에서도 언급했지만 개발자로 살아간다면, 자신이 사용하거나 사용할 기술들에 대하여 ‘왜 사용되어야 하는가?’ 라는 의문은 계속 제기하면서 살아야 한다고 생각한다. 그런 의미에서 이번 POJO 포스팅은 좀 더 개발다운 사람이 되는 시간이었다. 출처: https://javawork.tistory.com/entry/Java-POJO-Plain-Old-Java-Object https://okky.kr/article/415474","link":"/2022/04/26/Pojo%EB%9E%80/"},{"title":"RESTful API","text":"현대 애플리케이션은 대부분 프론트엔드라 부르는 클라이언트와 백엔드라 부르는 서버가 상호간 데이터를 주고받는 형태의 아키텍처를 가지고 있다. 이러한 구조의 가장 큰 특징중 하나는 서버와 클라이언트가 독립적으로 진화할 수 있다는 것이다.독립적으로 진화한다는 뜻은 각각의 업데이트 내용이 서로에게 영향을 미치지 않는 다는 것이다. 대표적인 예는 웹(web)이다. 웹 페이지의 변경이 브라우저에 영향을 미치지 못하고, 브라우저의 변경또한 페이지에 영향을 미치지 못한다. 서버와 클라이언트가 서로에게 영향을 끼치지 않고 독립적으로 진화하기 때문이다. 이러한 클라이언트 서버간의 독립적 진화를 위한 분산시스템 아키텍처로 가장 널리 쓰이는게 REST (Representatioin State Transfer) 아키텍쳐이다 REST(Representation State Transfer)REST는 2000년 HTTP의 주요 저자중 한 사람인 로이 필딩에 의해 제안되었다.그는 웹의 장점을 최대한 활용할 수 있는 아키텍처로써 REST를 발표하였고, 이를 통해 웹기술이 지속적으로 발전할 수 있게 되었다. 많은 사람들이 REST가 URI 패턴과 GET,POST 등의 HTTP Method 의 조합으로 이루어져 있다고 생각하지만,REST 아키텍처는 아키텍처라는 그 이름답게 결국 제약조건들의 집합이다. REST는 다음 여섯가지 제약조건을 가지고 있다. Client-Server Stateless Cache Uniform Interface Layered System Code On Demand(Optional) 각각에 대하여 살펴보도록 하자 Client-Server흔히들 이야기하는 서버와 클라이언트의 관계를 의미한다. 대부분 현대 애플리케이션은 서버-클라이언트 기반으로 만들어지고 사실상 이 구조를 벗어나는 것 자체가 힘든일이기 때문에 자연스럽게 만족되는 제약조건이라 할 수 있다. Stateless서버는 클라이언트의 각각의 요청을 모두 별개의 것으로 인식해야하고 이를 위해 모든 요청은 각자가 필요한 정보를 모두 담고 있어야 한다.요청 하나만 봐도 그 요청의 내용을 바로 알아볼 수 있어야 한다는 것이다. CacheHTTP라는 존재하는 프로토콜을 사용하기 때문에 웹에서 사용되는 기술인 캐시 역시 사용 가능하다.모든 서버응답은 캐시의 사용가능여부를 알고있어야하여, 캐시 사용을 고려한 설계가 필요하다. Uniform Interface구성요소들(서버,클라이언트)간의 인터페시으가 균일애햐 한다는 의미이다. 구체적으로 미디어 유형이나, 리소스 식별자 등을 구별하는 문법이 상호간 동일해야 한다는 뜻이다.이를 위해 REST는 네가지 제약사항을 제시하고 있다. identification of resources리소스를 식별하는 방법이 동일해야 한다. 흔히들 URI를 통해 리소스를 식별한다 manipulation of resources through representation리소스 자체를 전송하는 것이 아닌 리소스의 표현을 전송한다는 뜻. 서버에 있는 리소스가 아니라 현재 리소스의 상태를 반영하는 표현체를 전송함으로써 서버의 리소스 상태가 변해도 클라이언트에는 영향을 끼치지 못한다. self-descriptive messages요청이나 응답에는 스스로를 설명하는 정보를 포함하고 있어야 한다. 따라서 수신자는 이 정보를 통해 메시지를 이해할 수 있다. hypermedia as the engine of application state애플리케이션의 상태는 하이퍼미디어에 의해 변경된다는 것이다. 따라서 서버는 하이퍼미디어를 통해 다음 액션에 대한 선택지를 클라이언트에게 제공해야 한다. Layered System클라이언트 혹은 서버 모두 미들웨어 구성을 추가할 수 있는 구조를 가지고 있어야 한다는 의미이다. Code On Demand(Optional)서버는 클라이언트로 실행 가능한 프로그램을 전달할 수 있어야 한다. 쉽게 Javascript를 생각하면 된다. 그러나 이 조건은 선택사항이며 필수적이지는 않다. RESTful APIRESTful API(REST API)란 위의 제약조건에 따르는 애플리케이션 프로그래밍 인터페이스를 뜻한다. 그러나 우리가 RESTful API라고 부르는 것들은 사실 REST하지 않은 경우가 대부분이다. 특히, self-descriptve messages와 hypermedia as the engine of application state 원칙을 지키는 것이 상당히 까다로운 편이기 때문에 이 두원칙을 지키지 못하는 경우가 많다. 물론 로이 필딩은 이런 API를 REST라 불러선 안된다고 주장하지만 이미 많은 개발자들과 기업들은 REST 원칙을 지키지 못한 API들을 RESTful API라고 부르고 있다. 개인적인 생각원칙적인 REST 아키텍처 스타일을 알고있는 많은 사람들이 현대에 많은 글들과 회사에서 단지 몇가지 URL 규칙과 HTTP 메소드가 필요했을 뿐인 많은 사람들이 REST란 용어를 납치했다고까지 표현한다. 사실 개인적으론 이러한 논쟁이 머리아프게만 느껴지고 무슨 의미가 있나 싶기는 하지만, 이런 논쟁들이 좀 더 견고하고 표준화된 RESTful API 개념을 정립하는데 도움이 되겠거니 생각한다. 이런한 논쟁을 뒤로 하고 나는 결국 나만의 RESTful API를 정의 내렸다. Restful API란 HTTP URI(Uniform Resource Identifier)를 통해 자원(Resource)를 명시하고, HTTP Method(POST,GET,PUT,DELETE)를 통해 해당 자원에 대한 CRUD Opertaion을 적용한것.논란이 끝나면 새로운 정의가 나올 수 있겠지만 일단은 이렇게 알고있는게 마음편하다.","link":"/2022/03/26/RESTful-API/"},{"title":"Spring Batch","text":"Batch Program이란?일반적으로 배치(Batch) 프로그램이라 하면, 일련의 작업들을 하나의 작업단위로 묶어 연속적으로 일괄처리 하는 것을 말한다.예를 들어 하루전날의 집계된 요금데이터를 집계해야한다고 가정해보자. 이 업무는 하루에 1번만 수행하면 된다. 이를 위해 api를 구성하는것은 낭비가 된다. 또한 대량의 데이터를 처리하는 도중 실패가 된다면?? 이에 대한 처리를 어떻게 할 것인가? 이러한 단발성 대용량 데이터를 처리하는 프로그램을 배치프로그램이라 한다. 위에서 한 고민들을 살펴보면 단순히 집계하는 비즈니스 로직 이외에 고려해야할 부분이 많다는 것을 알 수 있다. 개발자가 비즈니스 로직 이외의 다른 부분들에 대한 고민을 덜어주도록 지원하는것을 프레임워크라 한다. 대표적인 프레임워크는 Spring이 있다. 그렇다면 Spring에서는 이런 배치프로그램을 지원하는 기능이 없을까? Spring 진영에서는 Spring Batch를 지원하며, 감히 말하건대 이 프레임워크가 Java개발자에게 있어서는 최선의 배치프레임워크라 자신한다. Spring Batch에 대해서는 아래에서 더 자세하게 다뤄보기로 하고 그 이전에 배치 프로그램이란 무엇인지 알고 넘어가도록 하자. 배치 프로그램이란 다음의 조건들을 만족하는 프로그램이다 대용량 데이터 - 대량의 데이터를 가져오거나, 전달하거나, 계산하는 등의 처리를 할 수 있어야 한다. 자동화 - 사용자의 개입 없이 실행되어야 한다. 견고성 - 잘못된 데이터를 충돌/중단 없이 처리할 수 있어야 한다. 신뢰성 - 무엇이 잘못되었는지 추적가능해야 한다(로깅, 알림) 성능 - 지정한 시간 안에 처리를 완료하거나 동시에 실행되는 다른 어플리케이션을 방해하지 않도록 수행되어야 한다. 자 이제는 이러한 배치프로그램의 개발을 지원하는 Spring Batch에 대해 더 자세하게 알아보자 Spring BatchSpring Batch는 2007년 Accenture와 SpringSource간의 협업으로 탄생하게 되었다. Accenture사의 배치업무에 대한 노하우와 SpringSouce의 기술력이 합쳐진 결과물이라고 할 수 있다. Spring Batch는 기본적으로 Spring의 특징 그대로를 사용할 수 있다. DI, AOP, 서비스 추상화 등의 스프링 프레임워크의 특징을 사용할 수 있으며, Accenture의 배치 아키텍쳐를 사용 할 수 있다는 의미이다. 여기에선 Spring Batch의 큰 줄기만 다뤄보도록 하겠다. 자세한 사용가이드는 공식 doc을 참고하면 된다.(https://docs.spring.io/spring-batch/docs/current/reference/html/) 위의 그림은 스프링 배치의 Job 구성에 관한 그림이다. 해당 그림에서 스프링의 큰 줄기개념들이 나오게 된다. 각각의 용어와 내용에 대해서 알아보도록 하자 JobSpring Batch에서 Job은 전체 배치 프로세스를 캡슐화하는 객체이다. 말이 어려울 수 있지만 쉽게 생각하면 결국 배치 프로그램을 이루는 업무단위의 최상위 계층이라고 생각하면 된다. Job은 사용자가 정의하기 나름이지만 최소한 1개의 Step으로는 이루어져 있으며, 복잡한 Job이 아닌 이상 2~10개의 Step을 권장한다. 배치 프로그램은 결국 여러개의 Job과 그 Job에 속해있는 여러개의 Step들로 이루어진다고 보면 된다. Step위에서 말했듯이 Step은 Job을 구성하는 요소이다. Step은 job의 독릭접으로 실행되는 순차적인 단계를 캡슐화한 도메인 객체이며, 실제 배치 처리를 정의하고 컨트롤하는 데 필요한 모든 정보를 가지고 있다.설명이 굉장히 모호하게 느껴질 수 있는데, 이는 Step의 모든 내용은 Job을 만드는 개발자의 재량이기 때문이다. 즉 개발자에 따라 Step은 간단할 수 도 있고 복잡할 수도 있다. 데이터베이스에서 데이터를 읽어서 파일을 쓰는 간단한 작업이 될 수도 있고, 프로세싱의 일부를 처리하는 복잡한 비즈니스 로직일 수도 있다. Step의 데이터 처리방법은 크게 두가지가 있다 Chunk지향 방식 Tasklet 방식 Spring Batch에서 추천하는 방식은 Chunk 지향방식이고 많은 사람들도 이 방식을 추천한다. 하지만 비즈니스로직이 Chunk 지향 방식으로 처리가 안되는 경우에는 Tasklet 방식을 사용할 수밖에 없다. Chunk 지향 방식 Spring Batch 구현체의 대부분은 ‘청크 지향’으로 개발되었다. 청크 지향 프로세싱이란 한 번에 데이터를 하나씩 읽어와서 트랜잭션 경계 내에서 쓰여질 ‘청크’를 만드는 것이다. 읽은 항목 수가 커밋 간격과 같아지면 ItemWriter가 청크 전체를 write하고, 트랜잭션이 컴ㅅ된다. 다음은 이 절차를 도식화한 그림이다. 다음 의사코드는 동일한 개념을 단순화된 형식으로 보여준다. 123456789List items = new Arraylist();for(int i = 0; i &lt; commitInterval; i++){ Object item = itemReader.read(); if (item != null) { items.add(item); }}itemWriter.write(items); Tasklet 방식 위에서 말했듯 청크 기반 처리로 구현할 수 없는 비즈니스 로직을 위해 Spring Batch는 TaskletStep을 제공한다. Tasklet은 excute 메소드 하나를 가진 심플한 인터페이스인데, 이 메소드는 RepeatStatue.FINISHED가 리턴되거나 실패했단 뜻으로 exception이 던져지기 전까지 TaskletStep을 반복적으로 호출한다. 각 Tasklet 호출은 트랜잭션으로 감싸져 있다. Tasklet을 실행하려면 빌더의 tasklet 메소드에 Tasklet 인터페이스를 구현한 빈을 넘겨야 한다. 1234567@Beanpublic Step step1() { return this.stepBuilderFactory.get(&quot;step1&quot;) .tasklet(myTasklet()) .build();} Quartz vs SpringBoot SchedulerSpring Batch의 큰 줄기는 위에서 다뤄봤다. 좀 더 자세한 설명과 예제가 필요하다면 공식 doc을 참고하길 바란다. 위의 내용을 읽었다면 배치 프로그램에서 중요한 부분이 빠졌다는 것을 알 수 있다. 바로 스케줄링 부분이다. 매일 또는 몇 시간 단위로 일정하게 프로그램을 실행시켜줄 스케줄러 기능이 Spring Batch에는 제공되지 않는다. 그래서 보통은 Quartz 라이브러리의 스케줄링 기능과 결합하여 많이들 사용하였다. 하지만 최근들어서는 SpringBoot에서 Scheudler 기능을 제공하기 시작했고, 이 기능과 묶어서 사용하는 케이스가 많아지게 되었다. 현재 내가 운영하는 시스템의 배치프로그램도 SpringBoot + Spring Batch 로 배치 프로그램이 동작하고 있다. 마치며서버개발자의 삶을 살아가다보면 배치프로그램의 개발은 피할 수 없는 일이 될 것이다. 위에서 소개한 Spring Batch는 그 개발 프레임워크로써 최고의 도구가 되기를 바란다.","link":"/2022/04/09/Spring-Batch/"},{"title":"Spring DI(의존성주입) &amp; IoC(제어의역전)","text":"Spring에서의 핵심 개념인 의존성주입(Dependency Injection, DI)과 제어의 역전(Inversion of Control, IoC)에 대해 알아보도록 하자. 두 개념은 사실 거의 같은 의미라고 할 수 있다. 의존성 주입은 외부에서 두 객체간의 관계를 결정해주는 디자인 패턴이고, 이 객체들의 사용에 대한 책임이 프레임워크에 있다는 것이 바로 제어의 역전이기 때문이다. 즉, Spring은 IoC를 통해 객체들의 의존성을 분리시켜 결합도를 낮춰주는 역할을 하고 있다. 의존성 주입(Dependency Injection)이란?위에서 DI에 대해 간략하게 소개하였지만 구체적인 예시를 들어 좀 더 명확하게 이해해보도록 하자. 예를 들어 다음과 같이 Cafe 객체가 coffee 객체를 사용하고 있는 경우에 우리는 Cafe객체가 Coffee객체에 의존성이 있다고 표현한다. 1234567public class Cafe { private Coffee coffee; public Cafe() { this.coffee = new Coffee(); }} 문제점위와 같은 Cafe와 Coffee클래스는 강하게 결합되어 있는 문제점이 있다. 만약 Cafe클래스에서 Coffee가 아닌 다른 Juice같은 상품이 필요하게 되면 Cafe클래스의 생성자에 변경이 필요하다.이는 유연성이 떨어진다는 의미이다. 또한 위의 Cafe와 Coffee는 객체들간의 관계가 아니라 클래스들간의 관계가 맺어져 있다는 문제도 있다. 올바른 객체지향적 설계라면 객체들간의 관계를 맺는것을 지향해야 한다. 해결책위와 같은 문제를 해결하기 위해서 우선 다형성을 활용해야 한다. Coffee, Juice등 여러가지 제품을 하나로 표현하기 위해 Beverage라는 Interface를 선언한다. 12public interface Beverage {} 12public class Coffee implements Beverage {} 이제 Coffee와 Cafe의 강한 결합을 제거해주도록 하자. 이를 제거하기 위해서 외부에서 Coffee를 주입(Injection) 받아야 한다. 12345678910public class Cafe { private Beverage beverage; public Store(Beverage beverage) { this.beverage = beverage; } } 12345678910public class CafeFactory { public void cafe(){ //Bean 생성 Coffee coffee = new Coffee(); //의존성 주입 Cafe cafe = new Cafe(coffee); }} 위와 같이 CafeFactory라는 외부에서 객체를 주입해줌으로써 의존관계를 재설정할 수 있다. Spring에서 CafeFactory의 역할은 Application Context가 수행하고 있다. 그리고 위에서 설명했듯이 객체를 사용하고 책임지는 역할이 사용자가 아닌 Spring Framework에 넘어가 있고 이러한 개념을 제어의 역전(Inversion of Control, IoC)이라고 한다. 정리Spring에서는 DI 컨테이너를 통해 서로 강하게 결합되어 있는 두 클래스를 분리하고, 두 객체간의 관계를 결정해줌으로써 결합도를 낮추고 유연성을 확보하고자 한다. Spring에서 이러한 객체들을 Bean이라 정의하고 있다. 또한 Spring에서는 이러한 Bean들을 성능을 위해 기본적으로 Sigleton으로 관리하고 있다. 마치며오늘은 DI와 IoC에 대해서 알아보았다. 오늘은 의존성 주입과 제어의 역전의 기본적인 개념에 대해서만 알아보았지만 좀 더 파고든다면 의존성 주입에도 여러 종류가 있다는 것을 알 수 있다. 이러한 개념들에 대해서는 좀 더 찾아보길 바라며 포스팅을 마치도록 하겠다.","link":"/2022/04/22/Spring-DI-%EC%9D%98%EC%A1%B4%EC%84%B1%EC%A3%BC%EC%9E%85-IoC-%EC%A0%9C%EC%96%B4%EC%9D%98%EC%97%AD%EC%A0%84/"},{"title":"Spring MVC","text":"최근 회사에서 SI프로젝트 지원을 나가게 되었다. 해당 프로젝트에서 사용하는 프레임워크가 Spring MVC였다. 해당 패턴에 대하여 다시한번 리마인드도 해볼겸 대부분의 웹 개발에 있어서 표준처럼 쓰이는 MVC 디자인 패턴에 대해 알아고보, 나아가 Spring MVC의 처리 과정까지 알아보도록 하겠다. MVC 패턴이란? MVC(Model-View-Controller) 패턴은 소프트웨어의 비즈니스 로직과 화면을 구분하는데 중점을 둔 디자인 패턴이다. 각 모델 뷰 컨트롤러는 다음과 같은 특징들을 가지고 있다. Model(모델)애플리케이션의 정보, 데이터의 가공을 책임지며 DB와 상호작용하며 비즈니스 로직을 처리하는 모듈, 컴포넌트를 말하며 아래와 같은 규칙을 가지고 있다. 사용자가 이용하려는 모든 데이터를 가지고 있어야 한다. View(뷰) 또는 Controller(컨트롤러)에 대한 어떤 정보도 알 수 없어야 한다 변경이 일어나면 처리 방법을 구현해야 한다. View(뷰)사용자 인터페이스 요소를 뜻하는데, Client에게 보여지는 결과화면을 반환하는 모듈을 말하며 아래와 같은 규칙을 가지고 있다. Model(모델)이 가지고 있는 데이터를 저장하면 안된다. Model(모델)이나 Controller(컨트롤러)에 대한 정보를 알면 안되며 닪순히 표시해주는 역할을 맡아야 한다. 변경이 일어나면 처리방법을 구현해야 한다. Controller(컨트롤러)Client 요청이 들어왔을 때 그 입력을 처리하고 어떤 로직을 실행시킬 것인지 Model(모델)과 View(뷰)를 연결해주며 제어하는 모듈을 말한다. Controller는 아래와 같은 규칙들을 가지고 있다. Model(모델) 또는 View(뷰)에 대한 정보를 알아야 한다. Model(모델) 또는 View(뷰)의 변경을 인지하여 대처를 해야한다. MVC 패턴 사용이유MVC 패턴의 사용목적이자 장점은 각 컴포넌트들이 서로 분리되어 자신의 역할에만 집중할 수 있게끔 개발을 하고 그렇게 만들어진 애플리케이션은 유지보수성, 확장성, 유연성등이 증가하고 중복코딩이라는 문제점이 사라지도록 한다는 것이다. MVC1 MVC1 패턴은 WAS(Web Application Server)내의 JSP에서 View와 Controller 역할을 모두 담당하는 패턴이다. 아키텍쳐가 간단하기때문에 작은 웹 어플리케이션을 제작할 때는 큰 무리가 없지만 대규모 웹 어플리케이션을 제작하는 경우 가독성이 떨어지고 유지보수에 어려움이 있다. 이를 보완하기 위해 MVC2 패턴이 등장하게 되었다. MVC2 MVC의 단점을 보완하기 위해 View와 Controller가 분리되었고 JSP는 로직 처리가 없는 단순히 Client에게 보여지는 View만을 담당하게 되었다. 현재의 모든 웹어플리케이션은 MVC2 패턴을 따르고 있고 우리가 알고 있는 Spring MVC 또한 MVC2 패턴을 따르고 있다. Spring MVC Spring 진영에서는 MVC2 패턴을 조금 더 발전시켜 Spring MVC 패턴을 선보였다. 위의 아키텍처에서 각 컴포넌트의 구조와 역할을 간단히 살펴보면, 프론트 컨트롤러가 우선적으로 클라이언트로부터 모든 요청을 받게 되며, 실제 요청의 처리는 개별 컨트롤러 클래스로 위임한다. 개별 컨트롤러 클래스는 핸들러라고도 하며, DI를 통해 생성해둔 Bean을 이용하여 비즈니스로직 처리 결과를 Model에 담아 다시 프론트 컨트롤러로 보낸다. 프론트 컨트롤러는 받은 Model을 알맞은 View 템플릿으로 전달하여 반영시키고, 최종적으로 클라이언트로 보낼 화면을 응답 결과로 전송한다. Spring MVC 실제 동작구조 위의 아키텍처는 Spring MVC의 실제 구조를 도식화 한것이다. 각각의 컴포넌트의 역할에 대해서 살펴보자 Dispatcher Servlet 사용자의 모든 요청을 받아서 처리하는 프론트 컨트롤러이다. 모든 Request를 각각의 컨트롤러에게 위임한다. Dispathcer Servlet을 프론트 컨트롤러가 가능하도록 설정하기 위해서는 web.xml에 명시하거나, org.springframework.web.WebApplicationInitializer 인터페이스를 구현하는 두가지 방식을 사용할 수 있다. Handler Mapping 요청을 직접 처리할 컨트롤러를 탐색한다. 구체적인 mapping은 xm파일이나 java config 관련 어노테이션 등을 통해 처리할 수 있다. Handler Adapter 매핑된 컨트롤러의 실행을 요청한다. Controller 직접 요청을 처리하며, 처리 결과를 반환한다. 컨트롤러에서 결과가 반환되면 Handler Adapter가 ModelAndView 객체로 변환되며, 여기에는 View Name과 같이 응답을 통해 보여줄 View에 대한 정보와 관련된 데이터가 포함되어 있다. View Resolver View Name을 확인한 후, 실제 컨트롤러부터 받은 로직 처리결과를 반영할 View파일(jsp)를 탐색한다. View 로직 처리 결과를 반영한 최종 화면을 생성한다. Spring MVC 동작 순서 클라이언트가 서버에 요청을 하면, 프론트 컨트롤러인 DispatcherServlet 클래스가 요청을 받는다. DispatcherServlet은 프로젝트 파일 내의 servlet-context.xml 파일의 @Controller 인자를 통해 등록한 요청 위임 컨트롤러를 찾아 매핑(mapping)된 컨트롤러가 존재하면 @RequestMapping을 통해 요청을 처리할 메소드로 이동한다. 컨트롤러는 해당 요청을 처리할 Service(서비스)를 받아 비즈니스 로직을 서비스에게 위임한다. Service(서비스)는 요청에 필요한 작업을 수행하고, 요청에 대해 DB에 접근해야 한다면 DAO에 요청하여 처리를 위임한다. DAO는 DB정보를 DTO를 통해 받아 서비스에 전달한다. 서비스는 전달받은 데이터를 컨트롤러에 전달한다. 컨트롤러는 Model(모델) 객체에게 요청에 맞는 View(뷰) 정보를 담아 DispatcherServlet에 전송한다. DispatcherServlet은 ViewResolver에게 전달받은 View 정보를 전달한다. ViewResolver는 응답할 View에 대한 JSP를 찾아 DispatcherServlet에 전달한다. DispatcherServlet은 응답할 뷰의 Render를 지시하고 뷰는 로직을 처리한다. DispatcherServlet은 클라이언트에게 Rending된 뷰를 응답하며 요청을 마친다. 출처: https://ss-o.tistory.com/160 https://velog.io/@gillog/a-j5c0h49n","link":"/2022/06/13/Spring-MVC/"},{"title":"객체지향 5원칙(SOLID)","text":"2000년대 초 로버트 마틴이 명명한 객체 지향 프로그래밍의 다섯가비 기본원칙을 마이클 페더스가 원칙의 앞글자를 따서 다시 SOLID라고 소개하였다.SOLID의 5대원칙은 다음과 같다. 단일 책임 원칙(Single Responsibility Principle) 개방 폐쇄 원칙(Open/Cloed Principle) 리스코프 치환 원칙(Liskov Subsitution Principle) 인터페이스 분리 원칙(Interface Segregation Principle) 의존관계 역전 원칙(Dependency Inversion Principle) 이 다섯가지 원칙애 대해 자세히 알아보도록 하자 단일 책임 원칙 : SRP(Single Responsibility Principle)모든 클래스는 하나의 책임만 가지며, 클래스는 그 책임을 완전히 캡슐화 해야함을 일컫는다.다시말해 클래스가 제공하는 모든 서비스는 단 하나의 책임을 수행하는데 집중되어야 한다는 뜻이다. SRP를 지키지 못하는 경우1234567891011121314public class 강아지 { final static Boolean 수컷 = true; final static Boolean 암컷 = false; Boolean 성별; void 소변보다() { if (this.성별 == 수컷) { // 한쪽 다리를 들고 소변을 보다. } else { // 뒷다리 두 개를 굽혀 앉은 자세로 소변을 본다. } }} 메소드에서 수컷, 암컷의 경우를 모두 구현하려고 하여 단일 책임 원칙을 위반하고 있는것을 볼 수 있다. SRP를 지키는 경우123456789101112131415abstract class 강아지 { abstract void 소변보다();}class 수컷강아지 extends 강아지 { void 소변보다() { // 한쪽 다리를 들고 소변을 본다. }}class 암컷강아지 extends 강아지 { void 소변보다() { // 뒷다리 두 개로 앉은 자세로 소변을 본다. }} 그래서 위와 같이 추상클래스를 두고 각각의 클래스가 자신의 특징에 맞게 메소드를 구현해서 사용하는것으로 리팩토링 할 수 있다. 개방 폐쇄의 원칙 : OCP(Open Closed Principle)개방-폐쇄 원칙은 소프트웨어 개체(클래스, 모듈, 함수 등)는 확장에 대해 열려 있어야 하고, 수정에 대해서는 닫혀 있어야 한다는 프로그래밍 원칙이다. 다시 말하면 요구사항의 변경이나 추가사항이 발생하더라도, 기존 구성요소는 수정이 일어나지 말아야 하며 쉽게 확장이 가능하여 재사용할 수 있어야 한다는 뜻이다.로버트 마틴은 OCP는 관리가 용이하고 재사용 가능한 코드를 만드는 기반이며, OCP를 가능케 하는 중요한 메커니즘은 추상화와 다형성이라고 설명한다. 비밀번호 암호화를 강화해야한다는 요구사항이 새롭게 들어왔다고 가정하자. 비밀번호 암호화를 강화하기 위해 다음과 같이 SHA-256알고리즘을 사용하는 새로운 PasswordEncoder를 생성하였다. 1234567public class SHA256PasswordEncoder{ public String encryptPassword(final String pw){ // SHA-256 암호화 메소드 }} 그리고 새로운 비밀번호 암호화 정책을 적용하려고 봤더니 UserService를 다음과 같이 수정해주어야 한다는 것이 발견되었다. 1234567public class UserService{ private final SHA256PasswordEncoder passwordEncoder; ...} 해당 코드의 문제가 보이는가?위 코드는 나중에 비밀번호 암호화 정책을 변경해야 한다는 요구사항이 온다면 또 다시 UserService에 변경이 필요해진다. 이는 기존의 코드를 수정하지 않아야 하는 개방 폐쇄 원칙에 위배된다.결국 이러한 문제를 해결하고 개방 폐쇄 원칙을 지키기 위해서는 추상화에 의존해야 한다. 12345678910111213141516171819202122public interface PasswordEncoder { String encryptPassword(final String pw); }public class SHA256PasswordEncoder implements PasswordEncoder { @Override public String encryptPaswword(final String pw){ ... }}public class UserService{ private final PasswordEncoder passwordEncoder; public void adduser(final String email, final String pw){ final String encryptedPassword = passwordEncoder.encryptPassword(pw); ... }} 개방 폐쇄 원칙이 본질적으로 얘기하고자 하는것은 결국 추상화이다. 이는 런타임 의존성과 컴파일 의존성이 객체 지향 프로그래밍에서는 동일하지 않다는 것을 의미한다. 리스코프 치환 원칙 : LSP(Liskov Substitution Principle)리스코프 치환 원칙은 1988년 바바라 리스코프가 올바른 상속 관계의 특징을 정의하기 위해 발표한 내용으로, 하위 클래스는 상위클래스의 모든 기능들을 수행 할 수 있어야함을 의미한다.즉 상위클래스을 사용하는 객체는 그 객체가 하위클래스로 변경되어도 문제없이 수행되어야 한다. 정말 당연한 원칙이지만 실무에서 좀처럼 지켜지지 않는 원칙중에 하나이다. 대부분의 경우 상위클래스의 메소드를 override하면서 문제가 발생하게 된다. 상위클래스의 기존 메소드를 하위클래스에서 잘못 수정하게 되면서 문제가 생기게 되는것이다. LSP를 잘 지키기 위해서는 override를 안하면 되는것이지만, 이는 절대적인 방법이 아니다.결국 상속을 할 떄 override가 필요하다면 상위클래스의 기능을 충실히 수행하고 기능의 추가만 신중하게 수행하면 된다. LSP는 결국 현재 하위클래스가 상위클래스의 기존 메소드의 의미를 해지지 않는지 신중히 고민을 하고 올바르게 상속하라는 의미이다. 인터페이스 분리의 원칙 : ISP(Interface Segregation Principle)인터페이스 분리 원칙은 클라이언트가 자신이 이용하지 않는 메서드에 의존하지 않아야 한다는 원칙이다. 다시 말하면 자신이 사용하지 않는 인터페이스는 구현하지 말아야 한다는 원칙이다. 하나의 큰 인터페이스를 상속받기보다는 인터페이스를 구체적이고 작은 단위들로 분리시켜 꼭 필요한 인터페이스만 구현하다는 의미이다. SRP가 클래스의 단일책임을 강조했다면 ISP는 인터페이스의 단일책임을 강조한다. 의존 역전 원칙 : DIP(Dependency Inversion Principle)의존 역전의 원칙은 다음과 같은 내용을 담고 있다. 상위 모듈은 하위 모듈에 의존해서는 안된다. 상위 모듈과 하위 모듈 모두 추상화에 의존해야한다. 추상화는 세부 사항에 의존해서는 안된다. 세부사항이 추상화에 의존해야한다. 의존 역전 원칙은 클래스 사이에는 의존관계가 존재하기 마련이지만, 구체적인 클래스에 의존하지말고 추상화에 의존하는 설계를 의미한다. 우리는 위의 예시들을 살펴보면서 의존 역전 원칙에 준수하도록 코드를 수정한 경험이 있다. 바로 OCP를 설명하기 위해 살펴봤던 SimplePasswordEncoder 예제가 DIP에 부합하는 리팩토링 과정이다. 예시에서 살펴보았든 의존 역전 원칙(DIP)는 개방 폐쇄 원칙(OCP)와 밀접한 관련이 있으며, 의존 역전 원칙이 위배되면 개방 폐쇄 원칙 역시 위배되게 될 가능성이 높다.","link":"/2022/03/26/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-5%EC%9B%90%EC%B9%99-SOLID/"},{"title":"모니터링 시스템(Prometheus, Grafana)(2)","text":"프로메테우스와 그라파나의 전체적인 아키텍처 및 설치과정을 알아보도록 하자 프로메테우스/그라파나 아키텍쳐지난 게시물에서도 말했듯이 프로메테우스는 데이터소스, 그라파나는 시각화 툴의 역할을 각각 맡고 있다. 또한 프로메테우스는 서버 뿐만 아니라 다양한 노드(컴포넌트)가 수집한 데이터를 pull방식으로 가져오는 구조이다. 여기서 node는 프로메테우스에서 제공하는 서비스일 수도 있고 사용자가 직접 커스텀한 Exporter일수도 있다.그 구조는 아래와 같다. 프로메테우스를 구성하는 컴포넌트들은 다음과 같다 Prometheus Server데이터를 수집하고 저장하는 메인서버 Exportertarget metric 데이터 수집Http 엔드포인트를 설정하여 서버에서 메트릭을 수집하도록 지원HAProxy, StatsD, Graphite와 같은 서비스를 지원 AlertManager설정한 규칙에 따른 알림 처리(Grafana 자체적으로 알람시스템을 가지고 있어 사용하지 않았음) PushGatewayExporter를 이용하여 수집이 어려운 작업에 대한 매트릭 pushing 지원 Grafana시각화 툴 Client LibrariesJava, Scala, Go, Python, Ruby 등의 언어에 대한 프로메테우 연동 라이브러리 현재 운영중인 모니터링 시스템의 경우 대부분은 Exporter로 데이터를 가져오고 있고, 알람은 Grafana의 알람체계를 사용하고 있다. 결국 Exporter를 각 시스템에 맞게 잘 구현하는것이 모니터링 시스템 구축의 핵심이라 할 수 있다. 프로메테우스 설치압축파일 다운로드현재 우리 서버에 설치된 버전은 2.19.0 버전이다 $ wget https://github.com/prometheus/prometheus/releases/download/v2.19.0/prometheus-2.19.0.linux-amd64.tar.gz $ tar xvfz prometheus-2.19.0.linux-amd64.tar.gz$ cd prometheus-2.19.0.linux-amd64 파일을 받은 후 압축까지 해제하여줍니다. 압축 해제후 설치과정은 따로 필요없습니다. 바로 prometheus 바이너리 파일이 실행 프로그램입니다. 설정파일설치된 폴더안에 prometheus.yml라는 YAML파일이 있습니다. # my global configglobal:scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.# scrape_timeout is set to the global default (10s). # Alertmanager configurationalerting:alertmanagers: static_configs: targets:# - alertmanager:9093 # Load rules once and periodically evaluate them according to the global ‘evaluation_interval’.rule_files:# - “first_rules.yml”# - “second_rules.yml” # A scrape configuration containing exactly one endpoint to scrape:# Here it’s Prometheus itself.scrape_configs:# The job name is added as a label job=&lt;job_name&gt; to any timeseries scraped from this config. job_name: ‘prometheus’ # metrics_path defaults to ‘/metrics’# scheme defaults to ‘http’. static_configs: targets: [‘localhost:9090’] globalPrometheus의 전반적인 부분에 대한 설정 scrap_interval : 정보를 수집하는 주기를 설정 evalutaion_interval : 시계열을 만들고 알람을 발생시키는 주기를 설정 rule_filesPrometheus 에서 불러올 rules 파일에 대한 경로를 지정하는 설정 scrape_configsPrometheus에서 어떤 자원을 모니터링할지 설정기본값으로 ‘prometheus’이 지정되어있는데 Prometheus 프로그램에서 발생된 시계열데이터를 수집결국 이 설정값에 exporter를 연결시켜 데이터를 수집하므로 주된 설정값임 프로메테우스 실행실행시에는 설정파일을 지정해줘야 한다. $ ./prometheus –config.file=prometheus.yml 실행을 확인하귀 위해 브라우저를 열어 http://localhost:9090 으로 접속하면 프로메테우스 UI 화면이 나타난다. 또한 프로메테우스가 어떤 메트릭 정보들을 제공하는지 확인하고 싶다면 http://localhost:9090/metrics 경로에서 확인할 수 있다. 위의 정보들은 실제로 운영중인 시스템의 모니터링 metric 값들이다. 해당 값들을 프로메테우스에 제공하기 위한 node exporter에 관한 이야기를 해보자 Custom Node ExporterPrometheus에서 제공되는 오픈소스 프로그램중 Node Exporter라는 것이 있다. Node Exporter의 종류는 굉장히 다양하고 Oracle, Mysql 등 DB에서 쿼리만 제공하면 데이터를 추출해주는 Exporter도 존재한다. 관련 Exporter는 공식 프로메테우스 공식 홈페이지를 통해 링크가 제공되니 참고해보기 바란다. 하지만 우리 시스템에서는 좀 더 커스텀된 데이터 가공이 필요하였고 결국 커스텀 Exporter를 만들기로 결정하였다. 어짜피 방식은 HTTP(REST) 방식이면 되니 개발은 간단하였다. 우리가 선택한 기술은 aws lambda 였고 이를 위해 serverless framework를 사용하여 exporter를 개발하였다. Serverless Framework과 lambda에 대해서는 추후에 더 자세하게 다뤄보도록 하겠다.api 구현방식이 중요한것이 아니라 프로메테우스가 원하는 metric 포맷으로 데이터를 리턴해주는 api가 존재하기만 하면 된다. api를 개발하는 방식은 굉장히 여러가지이니 개발자 재량껏 편한 방식으로 개발하면 된다. Lambda 언어는 node js를 선택하였고 프로메테우스 metric 데이터 형식으로 변환하기위해 ‘prom-client’ 를 패키지 관리자를 통해 설치하여 간편하게 metric 데이터 포맷으로 변환하였다. 해당 소스는 다음과 같다 소스 일부분만 가져왔지만 내용을 보면 sql라는 설정파일에 쿼리를 작성하면 원하는 내용으로 metric 데이터로 변환하여 준다. 위으 소스에서는 데이터를 Guage 형태로 가져왔는데 프로메테우스의 Metric 데이터 타입은 4가지로 나눠진다. Counter Guague Histogram Summary 해당 타입별 정의와 쓰임새는 공식홈페이지를 참고하기 바란다.(https://prometheus.io/docs/instrumenting/exporters/) 어쨌든 이런식으로 개발된 api의 엔드포인트를 prometheus.yml에 설정하여주면 위에서 보여준것과 같이 metric 데이터가 수집된다. 이제는 해당 데이터를 Grafana를 통해 시각화 해주면 된다.이에 대한 내용은 다음 포스트에서 다뤄보기로 한다.","link":"/2022/03/29/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EC%8B%9C%EC%8A%A4%ED%85%9C-Prometheus-Grafana-2/"},{"title":"모니터링 시스템 장애(1) - AWS Lambda 런타임 지원기한","text":"모니터링 시스템 요약현재 우리 시스템은 Prometheus와 Grafana를 통하여 모니터링 시스템이 구축되어 있다. Prometheus는 다양한 데이터를 직접 pooling하여 데이터를 저장하고, Grafana는 이 데이터를 시각화한다. 이 Prometheus가 pooling을 하는 방식으로 rest api를 사용하였고, 이 api를 제공하는 프로그램을 Exporter라고 한다. Promethues에서 제공하는 다양한 Exporter가 있지만 우리 시스템에서는 AWS Lambda를 Serverless Framework를 이용하여 이 Exporter를 커스텀하게 구축하였다. Exporter 배포 실패얼마 전 새로운 업무가 추가되고 모니터링 항목을 추가해야하는 작업이 진행되었다. 단순히 쿼리만 추가하여 Lambda를 재배포하면 되는 단순한 일이었다. 평소처럼 배포를 진행하던 중 cloud formation에서 해당 Lambda의 업데이트가 실패하였고 롤백을 시도하였으나 그마저도 실패하였다. 다시 재배포하기 위해서 sls deploy -v 를 계속해서 시도하였으나 실패 로그만 출력될 뿐이었다. 급하게 AWS 콘솔로 접근하여 cloud formation의 해당 스택의 작업을 수동으로 실행하고자 하였으나, 권한이 없어 시간이 지연되었다. 결국 문서에서 추천해주는 방법대로 aws cli를 실행하여 강제 롤백을 시도하였다.(https://aws.amazon.com/ko/premiumsupport/knowledge-center/cloudformation-update-rollback-failed/) 하지만 역시 해당 lambda 리소스에서 실패가 반복되었고, 명령어를 변경하여 리소스를 건너뛰고 시도하여 롤백에 성공하였다. AWS Lambda 런타임 지원 기한급한 불을 껐으니 이제 원인을 파악해야 할 때였다. Cloudformation 로그를 보기 시작하였고 해당 로그를 발견하였다. 결국 AWS Lambda의 nodejs 런타임 지원기한을 간과하고 있었던 것이다. 해당 지원 기간 종료는 공식 문서를 참고하면 된다.(https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/lambda-runtimes.html) 해당 기한을 참고하면 사용하던 nodejs10.x는 2022년 2월 14일 부로 지원이 완전종료되었다. 문제가 파악되었으니 이제 해결만 하면 되었다. 하지만 이를 해결하는 과정에서도 문제가 발생하였는데 이는 다음 포스팅에서 다뤄보도록 하겠다.","link":"/2022/06/03/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%9E%A5%EC%95%A0-1-AWS-Lambda-%EB%9F%B0%ED%83%80%EC%9E%84-%EC%A7%80%EC%9B%90%EA%B8%B0%ED%95%9C/"},{"title":"kinesis 중복레코드 처리(atleast once)","text":"Kiensis란?Kinesis는 실시간으로 데이터 스트림을 수집, 처리, 분석해주는 AWS 서비스이다. 데이터 스트림 수집 및 저장 샤드의 수를 조절하여 스트림을 얼마나 받을지 조절할 수 있음 데이터 중복이 일어나는 이유애플리케이션에 레코드가 두 번 이상 전달되는 주된 이s유는 두가지로 나눌 수 있다. 생산자 재시도 소비자 재시도 각각의 경우에 어떤 이유로 일어나는지 알아보자 생산자 재시도생산자재시도가 일어나는 가장 큰 이유는 네트워크 이슈문제일 가능성이 크다Kiensis 스트림에서 승인을 받기 전에 네트워크 관련 시간초과가 발생한다면 생산자는 레코드가 스트림에 전달되었는지 알 수 없다이러한 경우 동일한 데이터에 대해 PutRecord를 2번 이상 호출 할 수있다.(최대 3번까지 호출가능)중복을 철저히 방지해야하는 애플리케이션은 처리할 때 레코드에 기본키를 포함시켜서 처리해줘야 한다. 소비자 재시도사실 생산자 재시도보다는 소비자 재시도가 훨씬 더 많이 발생한다다음과 같은 경우에 동일한 샤읃의 레코드 프로세서가 중복실행된다 작업자가 예기치 않게 종료된 경우 작업자 인스턴스가 추가 또는 제거된 경우 샤드가 병합 또는 분할된 경우 애플리케이션이 배포된 경우 설명이 모호할 수 있으니 구체적인 예를 통해 흐름을 살펴보자샤드 1개와 샤드를 처리하는 작업자 1개가 있다고 가정해보자마지막 체크포인트가 레코드 번호 10000에 있다는 가정하에 다음의 이벤트 흐름을 살펴보자 작업자가 샤드에서 다음 레코드 배치(레코트 10001부터 20000까지)를 읽습니다 그런 다음 작업자가 레코드 배치를 연결된 레코드 프로세서로 전달합니다 레코드 프로세서가 데이터를 집계하고 Amazon S3 파일을 생성하며 파일을 Amazon S3로 업로드합니다. 새로운 체크포인트가 발생하기 전에 작업자가 예기치 않게 종료됩니다 애플리케이션, 작업자 및 레코드 프로세서가 다시 시작됩니다 이제 작업자가 마지막으로 성공한 체크포인트(여기서는 10001)에서 읽기 시작합니다 따라서 레코드 10001 ~ 20000이 두번 이상 소비됩니다 운영 시스템 해결방법위와 같은 이유로 중복레코드에 대한 상황이 발생할 수 있음을 인지하고 현재 운영중인 시스템에서는 이에대한 해결방법을 세웠다실제로 운영중인 시스템에서 각 레코드의 항목들에는 그 항목을 유일하게 결정지을 수 있는 key값이 들어가있다결국 해당 data insert문에 대하여 merge into 문법을 사용하여 중복되지않게 적재되도록 처리하였다","link":"/2022/03/25/kinesis-%EC%A4%91%EB%B3%B5%EB%A0%88%EC%BD%94%EB%93%9C-%EC%B2%98%EB%A6%AC-atleast-once/"},{"title":"Spring Framework란?","text":"Spring의 역사Spring Framework이 등장하기 전에는 EJB라는 기술을 통해 웹 애플리케이션을 개발하였다. 이 기술은 여러가지 복잡성으로 인해 사용하기 까다로웠고, 이러한 단점들을 보안하기 위한 기술들이 연구되었다. 그 과정에서 가장 호평을 받은 기술이 Spring Framework이다. 물론 Spring Framework가 처음부터 바로 나온것은 아니다. 2002년 로드 존슨은 자신이 출판한 저서(Expert One-on-One J2EE Design and Development)에 스프링의 핵심 개념과 기반 코드들을 소개하였다. 책 출간 직후 유겐 휠러와 얀 카로프가 로드 존슨에게 오픈 소스 프로젝트를 제안하였고, 전통적인 EJB라는 겨울을 넘어 새로운 시작이라는 뜻으로 Spring이라고 명칭을 짓게 되었다. Framework란?Spring은 항상 Fraemwork와 결합되어 Spring Framework라 불린다. 여기에서 사용된 Framework란 무엇일까?? Framework의 개념에 대해 설명할 떄 항상 Library와 비교되곤 한다. 두 개념이 유사한 점이 많아서일 것이다. 여기선 두 개념에 대한 공통점과 차이점에 대해 알아보고자 한다. Framework는 뼈대나 기반 구조를 뜻하고, 제어의 역전(IoC) 개념이 적용된 대표적인 기술이다. 소프트웨어에서의 프레임워크는 소프트웨어의 특정 문제를 해결하기 위해서 상호 협력하는 클래스와 인터페이스의 집합이라 할 수 있다.Library는 개발에 필요한 것들을 미리 구현해놓은 대상, 도구들의 집합을 말한다. 즉, 개발자가 만든 클래스에서 호출하여 사용하는 방식을 취하고 있다. Framework와 Library 모두 애플리케이션을 개발하는데 있어 쉽고 빠른 생산성을 위해 사용한다는 공통점을 가지고 있다. 이 둘의 가장 큰 차이는 바로 제어역전이다 관건은 애플리케이션의 흐름을 누가 쥐고 있느냐이다. Framework는 전체적인 흐름을 스스로 쥐고 있으면서 사용자는 그 안에서 필요한 코드를 짜 넣지만, Library는 사용자가 전체적인 흐름을 만들며 라이브러리를 가져다 쓴다. Spring FrameworkSpring Framework를 한 문장으로 표현한다면 ‘자바 엔터프라이즈 개발을 편하게 해주는 오픈 소스 경량급 애플리케이션 프레임워크’ 라고 할 수 있다. 즉, 애플리케이션 전 영역을 포괄하는 범용적인 프레임워크로써의 기능을 경량화하여(보다 쉽게 사용할 수 있게) 개발자에게 제공된흔 오픈소스 솔루션이라는 것이다. 이러한 스프링 프레임워크의 특징들을 하나씩 살펴보도록 하자. 경량 컨테이너경량 컨테이너로서 자바 객체를 직접 관리한다. 각각의 객체 생성, 소멸과 같은 라이프 사이클을 관리하며 스프링으로부터 필요한 객체를 얻어올 수 있다. POJO 기반의 구성POJO는 Plain Old Java Object의 약자로, 번역하면 평범한 오래된 자바 객체를 말한다. 마틴 파울러가 200년에 컨퍼런스 발표를 준비하다 만들어낸 용어인데, 중량 프레임워크들을 사용하게되면서 점점 무거운 객체를 만들게 된 것에 반발해서 사용되게 된 용어이다. 그 의미가 모호하고 와닿지 않을 수도 있다. 나 역시 의미가 잘 이해가 되지 않기에 추후에 POJO와 Spring에 대해 더욱 자세히 다뤄보도록 하겠다. 다만 토비의 스프링에서는 진정한 POJO란 객체지향적인 원리에 충실하면서, 환경과 기술에 종속되지 않고 필요에 따라 재활용 될 수 있는 방식으로 설계된 오브젝트라고 설명하였다. 이러한 Spring의 핵심적인 내용인 POJO에 대해서는 다음 포스팅에서 다뤄보도록 하겠다. IOC와 DI 지원컨트롤의 제어권이 사용자가 아니라 프레임워크에 있어서 필요에 따라 스프링에서 사용자의 코드를 호출한다. 이것을 제어의 역행(IoC)라고 한다.의존성 주입(DI)는 제어의 역행이 일어나는 것을 전제로 하여 스프링 내부의 객체들간의 관계를 만들어 줄 떄 사용된다. 말 그대로 특정 개체가 필요로 하는 객체를 외부에서 결정하여 연결시키는 것을 말한다. 이 또한 Spring의 핵심특징중 하나로 자세하게 다루기엔 길어지므로 다음 포스팅에서 다뤄보도록 하겠다. AOP 지원AOP(Asepect Oriented Programming)는 관점 지향 프로그래밍을 뜻한다. 대부분의 시스템에서 비즈니스 로직은 아니지만 보안, 로그, 트랜잭션과 같이 반드시 처리가 필요한 부분을 횡단 관리 심사라고 한다. 스프링에서는 이러한 관심사를 비즈니스 로직과 분리하여 중복된 코드를 줄이고 개발자가 비즈니스 로직에 집중하도록 만들어준다. 이 또한 방대한 내용이므로 따로 포스팅하도록 하겠다. WAS에 독립적인 개발환경과거의 EJB가 동작하려면 고가의 느리고 무거운 자바 서버(WAS)가 필요했다. 그에 반해 스프링은 가장 단순한 서버환경인 톰캣(Tomcat)이나 제티(Jetty)에서도 완벽하게 동작한다. 더군다나 Spring Boot에서는 자체 내장된 WAS를 사용하여 별도의 tomcat등을 설치할 필요도 없게 되었다. 이에관해 Spring Boot의 내장 WAS의 성능에 대해서 다뤄보는 포스팅을 추후세 작성하도록 하겠다. 마치며여기까지의 내용은 스프링의 맛만 보았다고 할 수 있다. 위에서 언급된 내용들을 좀 더 구체적이고 심화된 내용으로 다뤄보는 시간을 가지도록 하겠다.","link":"/2022/04/19/Spring-Framework%EB%9E%80/"},{"title":"모니터링 시스템(Prometheus, Grafana)(3)","text":"앞서 말했듯이 Grafana는 시계열 데이터를 시각화하는데 가장 최적화된 대시보드를 제공해주는 오픈소스 툴킷이다. 주로 InfluxDB, Prometheus, Graphite등의 시계열 데이터베이스와 함께 사용되며 실시간 데이터분석, 모니터링등에서 많이 사용되고 있다. 특히 자체적인 Alert기능 제공은 해당 툴을 선택하는데 가장 큰 이유가 되었다. Grafana 설치Grafana를 설치과정은 공식사이트를 통해 자세하게 나와있다.(https://grafana.com/grafana/download) 공식문서에서 제공하는것처럼 설치과정을 따르고 나면 압축 해제된 폴더의 bin 디렉토리로 이동하여 grafana 서버를 실행시킬 수 있다. $ cd [압축 파일을 해제한 폴더]/bin$ ./grafana-server or grafana-server start 운영체제가 Redhat 계열이라면 아래 서비스 실행 명령어로 바로 실행시킬 수 있다. $ sudo service grafana-server start 실행 후 3000번 포트로 접근하면 아래와 같은 대시보드 화면이 나오게 된다. Grafana 웹 서버의 초기 username/password 는 admin/admin 이다. 로그인이 완료되면 비밀번호를 변경하를 페이지가 뜨는데 원치 않는다면 skip을 누르면 된다. 대시보드 구성그라파나 설치 후 모니터링 대시보드를 구성하기 위한 방법을 여러가지이지만, 꽤나 번거로운 작업이기에 외부 대시보드 포맷을 사용한다면 좀 더 쉽게 구성할 수 있다. 아래 사이트에서 각종 대시보드 포맷을 둘러보고 선택해서 사용하면 된다https://grafana.com/grafana/dashboards/ 위와같은 대시보드 포맷을 사용하지 않고 각자 데이터 소스를 선택하고, 데이터를 편집하여 고유 화면을 구성할 수도 있다. 현재 우리 시스템같은 경우는 Prometheus와 CloudWatch를 데이터소스로 사용하여 대시보드 화면을 구성하고 있다. 위와 같은 아키텍쳐를 기반으로 설계된 모니터링 대시보드는 다음과 같다 각자의 시스템에 맞는 대시보드를 꾸며 최적의 모니터링 화면을 설계해보도록 하자!","link":"/2022/03/29/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EC%8B%9C%EC%8A%A4%ED%85%9C-Prometheus-Grafana-3/"},{"title":"모니터링 시스템(Prometheus, Grafana)(1)","text":"2018년 유지보수중이던 시스템이 기존 NT 서버에서 AWS로 모든 인프라를 옮기는 대공사를 진행하게 되었다.인프라 전면전환 작업은 2년 가까운 시간이 되어서야 반영이 되었고, 2020년경부터 새로운 AWS인프라 위의 시스템을 유지보수하기 시작했다. 각종 문제들이 많이 생기기 시작했지만 가장 시급한 문제는 모니터링 시스템의 부재였다. 현재 내가 운영하고 있는 시스템은 실시간 대용량 트랜잭션을 처리하는 시스템으로, 장애발생시 5분 이내에 복구조치가 되도록 계약되어 있었고, 이를 위해서 모니터링 체계 구축은 필수적인 작업이었다. 많은 조사가 있었고 결국 우리는 프로메테우스와 그라파나라는 오픈소스를 사용하여 모니터링 체계를 구축하기 시작했다. 왜 프로메테우스인가?회사생활을 하다보면, 아니 개발자로서 살아가다보면 기술을 이유없이 의미없이 가져다 쓰는 경우가 굉장히 많다. 얼마전 지인으로부터 모니터링 시스템에 관해 이야기하다 프로메테우스를 선택한 이유에 대한 질문을 받게되었다. 답변을 하기 위해 횡설수설 프로메테우스의 장점에 대해 이야기했지만, 막상 생각해보니 시스템을 구축할 당시 많은 고민을 해보고 선택하지는 않았음을 깨달았다. 물론 그 당시 나름의 이유가 있었지만 잘 기억이 안나기에 다시 한번 리마인드 하기 위해 관련 내용을 정리해보고자 한다. Prometheus 장점프로메테우스 Github에서 설명하고 있는 장점들은 다음과 같다. 다차원 데이터 모델 가능 다차원 데이터 모델을 활용할 수 있는 유연한 쿼리언어(PromQL) 분산 스토리지에서 어떠한 의존성도 없음 모든 데이터는 HTTP(REST) Pull 기반으로 가져온다. 물론 Push도 가능함 모니터링 타겟은 프로메테우스의 YAML 설정값을 통해 Discovery 많은 장점들이 있지만 결국 프로메테우스의 가장 큰 특징이자 장점은 Pull방식의 모니터링 오픈소스라는 점이다. Pull 방식이란 대상 애플리케이션의 Exporter Enpoint로부터 데이터를 scrape 해오는 방식을 말한다.이 방식 덕분에 모니터링 설정을 Data Backend에서 효율적으로 관리할 수 있고, 혹시라도 Prometheus 장애 발생시에도 애플리케이션에 지장이 가지 않을수가 있다.위와 같은 장점들이 결국 프로메테우스를 선택하게 된 가장 큰 이유가 되었다. 물론 프로메테우스가 장점만 존재하는것은 아니다. 이제부터는 프로메테우스의 한계점에 대해 알아보고자 한다. Prometheus 한계점 클러스터링 구조에 대한 미지원 프로메테우스는 좋은 모니터링 시스템이긴 하지만 결정적인 문제점들이 있다. 그 첫번째가 바로 클러스터링 구조에 대한 미지원 문제이다. 이는 확장성과 가용성에 문제를 가져오게 된다. 확장성시스템에서 모니터링 할 대상들이 많지 않다면 하나의 프로메테우스 서버로 감당이 가능하겠지만, 볼륨이 늘어난다면 버거워지기 마련이다. 이 문제를 해결하는 방법으로 Federation 이라는 방법을 사용한다. 프로메테우스 인스턴스를 여러개 기동한 다음, 중앙에 다른 프로메테우스로부터 메트릭을 수집하는 중앙 집중 프로메테우를 놓는 방식이고, 데이터 양에 대한 문제는 데이터 해상도를 줄이거나 평균, 합등의 대표값을 사용해서 해결 할 수 있다. 가용성프로메테우스는 하나의 서버로 기동되기 때문에 그 서버가 장애로 내려갈 경우, 그 시간동안은 매트릭을 수집할 수 없다는 단점을 가지고 있다. 이를 해결하기 위해서는 프로메테우스 인스턴스를 두개 이상 띄운 다음 같은 대상 시스템으로부터 매트릭을 수집하는 방식인데 이렇게 되면 해당 문제를 해결 할 수 있기는 하다. 위의 아키텍쳐들은 역시 클러스터링의 대용일 뿐 제대로 되어 보이지는 않는다. 이를 해결하기 위해 오픈소스 타노스가 나왔지만 이는 나중에 다뤄보도록 한다. 오래 된 값 저장 프로메테우스의 다른 문제점 중 하나는 로컬 디스크를 사용하기 때문에 일정 기간이 지나 오래된 데이터는 삭제가 된다는 점이다. 그래서 오래된 데이터에 대한 조회가 불가능하다. 물론 이 문제에 대한 해결책 또한 오픈소스 타노스를 이용한다면 어느정도 해결이 되겠지만 이는 다루는 내용을 벗어나므로 다루지 않겠다. 이러한 한계점들이 존재하지만 현재 운영시스템에서는 위와 같은 한계들을 인정하고서라도 프로메테우스의 장점을 높이 쳐줬기에 선택하게 되었다.현 시스템이 그렇게 크지 않기때문에 클러스터링 구조는 필요가 없을것이라 판단했고, 오래된 값 또한 아쉽긴 하지만 실시간 모니터링에 초점을 두다보니 크게 문제가 되지 않았다. 왜 Grafana인가?프로메테우스와 달리 그라파나는 초기 선택에 있어서 큰 고민이 필요하지 않았다. 많은 자료들을 찾아봐도 프로메테우스와 그라파나는 거의 짝궁처럼 붙어다니는 기술이었기 때문이다. 하지만 그라파나 또한 장단점이 있으니 이에 대해 알아보도록 하자. Grafana 장점공식 홈페이지를 통해서 말하고 있는 그라파나의 장점은 다음과 같다. 데이터베이스가 아닌 데이터 통합 Grafana에서는 데이터를 수집할 필요가 없다. 대신 기존 데이터들을 통합하여 시각화 하는 방식을 취합니다. 누구나 사용할 수 있는 대시보드 Grafana 대시보드는 다양한 소스에서 수집된 데이터를 다른 팀원과 공유하여 함께 데이터를 탐색할 수 있습니다. 누구나 동적 대시보드를 만들고 공유하여 협업과 투명성을 높일 수 있습니다. 누구나 볼 수 있는 데이터 Grafana는 단일 담당자가 아니라 조직의 모든 사람이 데이터에 엑세스 할 수 있어야 한다는 원칙에 따라 구축되었다. 데이터를 민주화함으로써 필요로 하는 사람들이 데이터를 쉽게 사용하고 액세스 할 수 있는 문화를 촉진하여 팀의 역량을 강화하는데 도움이 된다. 유연성 및 다용성 모든 데이터를 유연하고 다용도 대시보드로 변환한다. 고급 쿼리 및 변환 기능을 사용하여 패널을 사용자 정의하여 실제로 도움이 되는 시각화를 생성 할 수 있다. 위와 같은 장점들이 공식 홈페이지에서 설명하는 장점들이지만 사실 이러한 장점들은 다른 시각화 툴도 가지고 있는 장점들이다. 내가 생각하는 그라파나의 가장 큰 장점들은 다양한 데이터 소스와의 연동, 그리고 손쉬은 Alert 기능 추가라고 생각한다. 서론이 너무 길었고 이제부턴 프로메테우스 &amp; 그라파나의 설치 및 시스템 구축에 대해 다뤄보자","link":"/2022/03/28/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EC%8B%9C%EC%8A%A4%ED%85%9C-Prometheus-Grafana/"},{"title":"모니터링 시스템 장애(2) - node-oraclelib 버전 호환성","text":"지난 포스팅에서 언급한것처럼 오늘은 nodejs 버전 업그레이드 과정에서 생긴 모니터링 시스템 장애에 대해서 말해보고자 한다. Serverless Framework nodejs 버전 업그레이드Serverless Framework에서 nodejs 버전업그레이드는 정말 간편하다. serverless.yml 파일의 provider 의 runtime만 nodejs14.x로 변경해주면 된다. 이렇게만 설정해주면 해당 yml을 참고하는 모든 lambda의 nodejs 버전이 업그레이드 된다. 이 간편함때문에 내가 serverless framework를 즐겨쓴다. 이번 nodejs 버전 업그레이드는 위에서 설명한것처럼 간단하게 진행되었다. 버전 명시후 재배포를 진행하였고 문제없이 배포되었다. 하지만 약 1분뒤 lambda를 사용하는 모든 모니터링에서 알람이 울리기 시작했다. 바로 망했다는 생각이 들었고 수많은 lambda 중 하나를 골라 CloudWatch상의 로그를 보기 시작하였다. 라이브러리 버전 호환성위와 같은 로그가 보이기 시작하였다. 바뀐게 없는데 왜 저런 오류가 날까 한참을 고민하다 사용하던 oracle lib 버전이 현재 nodejs와 호환이 되지 않을수 있다는 생각이 들었다. 예상대로 현재 사용되는 버전은 4년전에 사용되던 버전이었고 최신버전으로 업그레이드 이후 다시 재배포하였다. 이후 모든 수치들은 정상으로 돌아오게 되었다. 마치며다행히 모든 모니터링 수치는 정상으로 돌아왔지만, 문제가 생긴 1시간정도 정말 식은땀을 흘렸던거 같다. 이번 경험을 통해 느낀바는 두가지이다. AWS의 기술 지원 기간을 잘 확인해야 한다는 점 버전 업그레이드시에는 각 라이브러리와의 호환성 체크가 필수라는 점 이렇게 또 한번의 경험을 통해 성장하는 계기가 되었다.","link":"/2022/06/03/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%9E%A5%EC%95%A0-2-node-oraclelib-%EB%B2%84%EC%A0%84-%ED%98%B8%ED%99%98%EC%84%B1/"},{"title":"AWS Lambda를 이용한 Restful API서비스 개발(2)","text":"지난 포스팅서는 Lambda의 개념과 과금체계에 대해서 알아보았다. 오늘은 이 람다를 이용한 Restful API 개발방법에 대해 알아보도록 하겠다. AWS ApiGateway람다는 서버가 필요없고 자동으로 Scale Up, Scale Down된다는 점에서 Rest API를 개발하는데 굉장히 유리하다. 하지만 람다는 그 자체만으로는 동작할 수 없기에 실행을 촉발히켜주는 트리거가 필요하다. API Gateway는 URL 요청을 받아 람다를 실행시켜주는 AWS의 서비스이다. 이 서비스를 이용하면 추가적인 장점들이 따라오는데 우선 https통신방식을 기본으로 설정해주기 때문에 SSL에 대해 고민할 필요가 없다. 또한 권한부여자 기능을 통해 api인증기능을 아름답고 쉽게 구현할 수 있도록 지원하고 있다. 최종적으로 람다를 이용한 REST API아키텍쳐는 다음과 같을것이다. Serverless Framework위와 같은 구조로 개발을 진행하기 위해서는 각 서비스들을 생성하고 설정해주는 작업들이 필요하다. 우선 콘솔상에서 직접 각 서비스들을 만들기 위해서는 다음과 같은 과정이 필요하다. AWS 콘솔 로그인 Lambda 생성 트리거 API Gateway 지정 API Gateway 생성 테스트 이와 같은 과정이 새로운 API가 추가될때마다 N번 반복되게 된다. 위와 같은 방식은 테스트가 용이하지도 않으면서, 서비스가 커지게 된다면 너무나 비효율적이라 할 수 있다. 이 문제를 해결하기 위해 Lambda개발을 지원하는 다양한 프레임워크가 있다. 대표적으로 AWS에서 제공하는 SAM과 Serverless Framework가 존재한다. 이번 프로젝트에서는 기존에 사용했던 Serverless Framework를 사용하기로 결정하였다. Serverless Framework 공식페이지에는 Lambda와 API Gateway를 이용한 Rest API 구현 예제를 제공하고 이 예제를 통해 초기 셋업을 진행하면 된다.(https://www.serverless.com/examples) Serverless OfflineLambda 개발을 진행하다보면 매번 테스트를 배포해서 해야하는 번거로움이 있다. Serverless Framwork진영에서는 이 문제를 해결하기 우해 Serverless Offline이라는 플러그인을 제공하고, 이를 통해 로컬에서 API테스트를 진행 할 수 있다.(https://www.npmjs.com/package/serverless-offline) 마치며오늘은 API Gateway와 Serverless Framework에 대한 내용을 정리하였다. Lambda의 런타임을 선택할 떄는 보통 파이썬, Go, Node.Js를 선택하는데 이는 Lambda의 Cold Start시간과 연관이 있다. 다음 포스팅에서는 Lambda의 Cold Start시간에 대해서 알아보도록 하겠다.","link":"/2022/07/12/AWS-Lambda%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-Restful-API%EC%84%9C%EB%B9%84%EC%8A%A4-%EA%B0%9C%EB%B0%9C-2/"},{"title":"Netty Hashed Wheel Timer","text":"오랜만의 포스팅하는 오늘의 주제는 Netty의 HashedWheelTimer에 대한 분석글이다. 해당 Timer의 장점과 사용이유 Java의 Timer의 한계점 등에 대해서 소개해보려 한다. Java.util.TimerJava는 기본적으로 Timer 객체를 제공하고 있다. 사용법은 TimerTask를 생성하여 Timer에 등록한 후 시간값을 입력하여주면 된다. 그 예시는 다음과 같다. 1234567891011121314151617import java.util.Timer;import java.util.TimerTask;public class Main { public static void main(String[] args) { Timer m = new Timer(); TimerTask task = new TimerTask() { @Override public void run() { System.out.println(&quot;timer!&quot;); } }; m.schedule(task,5000);// 5초 뒤에 실행 }} 사용법은 간단하지만 빈번한 타이머 사용의 경우, 해당 클래스로는 좋은 성능을 내기 힘들다. java.util.Timer 객체는 내부적으로 TimerTask를 binary heap 구조로 관리하기 떄문에 TimerTask 추가, 삭제시 일어나는 동기화시간이 길어질 수 밖에 없다. 다음은 타이머 객체의 동기화 코드이다. 이런 동기화시간의 장기화는 프로그램의 성능을 저하시킬 수 밖에 없다. 최근 Timer 기능을 사용하여 업무를 설계해야 하는일이 발생하였고 위와 같은 문제점을 알고있었기에, TimingWheel 자료구조를 사용하는 Netty의 HashedWheelTimer 객체를 사용하기로 하였다. Timing WheelTimingWheel 의 기본구조는 고정된 크기의 순환배열이다. 배열의 각 버킷을 타임슬롯(time slot)이라고 부르고, 해당 슬롯은 타임아웃이 발생할 떄 처리해야할 작업에 대한 리스트를 담고있다. 기본적인 동작과정은 슬롯 시간 간격마다 타임슬롯을 순회하며, 해당 타임슬롯에 담긴 내용을 처리하는 방식으로 이루어진다. 해당 타임 슬롯에 타임아웃을 추가하는 경우 단순히 add연산자를 통해 추가할수 있으므로, java의 타이머에 비해 동기화시간히 짧아지게 된다. HashedWheelTimer위에서 언급한 휠 타이머는 최대 시간 제한이 있다는 단점이 있다. 타임슬롯을 넘어가는 값을 등록할 수가 없는것이다. 이러한 단점을 극복하기 위해 Netty의 HashedWheelTimer는 남은 바퀴수까지 계산하여 등록시간제한문제를 해결하였다. 마치며오늘은 POJO의 등장배경에 대해 알아보았다. 이 포스팅을 정리하며 EJB부터 Spring까지 Java 서버개발의 역사에 대해 전반적으로 알 수 있었다. 사실 EJB에 대해서 정확하게 알 수는 없지만 Spring, Pojo의 등장 배경에 대해 좀 더 잘 이해할 수 있는 시간이어서 의미있는 시간이었다. 이전 포스팅에서도 언급했지만 개발자로 살아간다면, 자신이 사용하거나 사용할 기술들에 대하여 ‘왜 사용되어야 하는가?’ 라는 의문은 계속 제기하면서 살아야 한다고 생각한다. 그런 의미에서 이번 POJO 포스팅은 좀 더 개발다운 사람이 되는 시간이었다. 출처: https://d2.naver.com/helloworld/267396","link":"/2022/08/30/Netty-Hashed-Wheel-Timer/"},{"title":"DB 엔진 업그레이드시 유의사항","text":"최근 회사에서 오라클 버전 업그레이드 작업이 진행되었다. 기존 11g의 지원기간(EOS)가 2022년 7월까지였고, 정말 하기 싫었지만 업그레이드 작업은 필수가 되었다. 현재 지원되는 오라클 버전중 19c가 가장 EOS기간이 긴 버전이었고 해당 버전으로 업그레이드가 진행되었다. 업그레이드를 진행하면서 난감한 상황과 아찔한 상황들을 많이 겪었는데, 업그레이드를 앞둔 다른 개발자들에게 조금이라도 도움이 되었으면 하는 바램으로 해당 내용들을 공유하고자 한다. 다운타임에 대한 대책첫번째로 고려할 사항은 다운타임에 대한 대책을 세워야 한다는 점이다. AWS Oracle RDS 메이저버전 업그레이드시에 1시간 가량의 다운타임이 생기는데 이 상황에서 기존 서비스들이 어떤 방법으로 대응해야하는지 계획을 세워야 한다. 내가 회사에서 운영중인 시스템의 경우 실시간 처리시스템이지만, 데이터가 우선 Kinesis로 들어와 각 서비스로 분기처리 되기 떄문에 DB 다운타임 발생시, DB적재 서비스만 잠시 멈춰두었다 작업 이후 실행시켜주면 되었다. 이런식으로 잘 짜여진 아키텍쳐라면 영향도를 최소화하며 작업을 진행할 수 있기때문에 시스템 구축시 아키텍쳐가 얼마나 중요한지 알 수 있었다. JDK별 JDBC버전 확인Oracle Database의 Java프로그램 DB커넥션은 oracle에서 제공해주는 ojdbc 라이브러리를 통해 맺어지게 된다. 공식사이트에 가게되면 Oracle 엔진 버전과 Jdk버전에 호환되는 ojdbc 버전이 명시되어있다. 물론 해당 ojdbc 버전을 사용하지 않는다고해서 문제가 꼭 생기지 않을수도 있다. 하지만 우리 회사에서 진행된 오라클 버전 업그레이드 작업에서는 해당 문제가 발생하였다. 기존에는 ojdbc6.jar파일을 사용하였는데, ojdbc라이브러리의 버전 호환성을 생각하지 못하고 각종 테스트를 진행하였다. 모든 기능과 성능에서 문제가 없다고 판단되어 반영을 3일 앞둔 시점에 테스트중이던 배치프로그램에서 문제가 발생였다. 잘 수행되던 배치 프로그램이 갑자기 커넥션을 맺는데 시간이 점점 늘어나더니, 기존에 5초정도면 수행되던 배치가 10분 20분이 걸리기 시작한 것이다. 패닉상황이었지만 결국 ojdbc버전 호환성 문제임을 인식하고 해결을 하였지만, 전 프로그램에 대해서 테스트 재수행과 라이브러리 버전업그레이드로 인한 소스 수정은 불가피했다. 이와같은 상황이 발생하지 않도록 아래의 oracle 버전과 jdk버전에 따른 ojdbc라이브러리 버전을 잘 확인해보기 바란다. [자료출처] https://www.oracle.com/database/technologies/faq-jdbc.html 응용서비스 SQL전수검사DB전환작업을 진행하게 되면 전체적인 쿼리에 대한 검사가 필요하다. 기본적이 기능검사는 물론 성능검사가 필수이다. 오라클 버전이 업그레이드 되면서 기존에 지원되던 함수가 실행되지 않을수도 있고, 빠르게 수행되던 쿼리가 느리게 수행될 수도 있다. 우리의 이번 업그레이드 과정에서는 기존에 3분정도 걸리던 배치수행쿼리가 20분 이상 걸리는 현상이 발견되었다. 업그레이드 된 데이터베이스에서 쿼리 작성자가 의도했던 인덱스를 타지 않았던 것이 원인이 되었다. 이 경우 의도한 인덱스를 타도록 힌트를 주어 해결하였다. 데이터베이스 사설IP 변경대응RDS가 업그레이드 되는 과정은 새로운 RDS를 생성하여 기존 데이터베이스와 바꿔치는 과정이다. 이 과정에서 도메인 주소는 기존과 동일하지만, 사설 IP는 변경이 될 수 밖에없다. 타 시스템 혹은 우리 시스템 내부에서도 사설IP를 통해 운영되는 서비스가 있다면 버전 업그레이드 작업 진행과 동시에 IP변경작업도 진행해주어야 한다. 기존에 타 시스템과 우리시스템의 결합도를 미리 파악하고 사전 공유해주는게 굉장히 중요하다고 할 수있다. 이번에 진행된 우리 시스템에서는 이 부분을 놓쳐 연계솔루션 팀과 빅데이터 파트와의 연결이 끊어져, 해당파트에서 주말동안 복구작업을 진행하였다고 전달받았다. 이러한 불상사가 생기지 않도록 미리 잘 파악해야 한다. Character set, 인코딩 이슈해당 이슈는 내가 겪었던 이슈는 아니지만 많은 사람들이 오라클 데이터 전환작업에서 유의할 사항으로 뽑았기에 추가해 보았다. 기존 데이터에서 지원되던 character set이 19c에서는 지원이 안되는 경우가 있다고 한다. 해당 이슈는 꽤나 큰 문제가 될 수 있으니 미리 체크를 하여, 업그레이드 될 데이터베이스에서 지원해주는 캐릭터셋으로 미리 변경하여 영향도를 최대한 감수할 필요가 있다. 마치며이번 포스팅에서는 회사에서 진행된 오라클 버전업그레이드시 내가 겪었던 다양한 상황들에 대해서 다루어 봤다. 위에서 다룬 이슈들 이외에 많은 유의사항이 있겠지만 아직 능력이 부족해 다 파악하지는 못했던거 같다. 앞으로 연차가 더 쌓이면 위에서 언급한 실수들도 더이상 안하게 되고, 더 깊이 있는 내용까지 신경쓸 수 있겠지 라고 생각한다… 출처: https://ojava.tistory.com/164","link":"/2022/07/18/DB-%EC%97%94%EC%A7%84-%EC%97%85%EA%B7%B8%EB%A0%88%EC%9D%B4%EB%93%9C%EC%8B%9C-%EC%9C%A0%EC%9D%98%EC%82%AC%ED%95%AD/"}],"tags":[{"name":"AWS","slug":"AWS","link":"/tags/AWS/"},{"name":"Serverless","slug":"Serverless","link":"/tags/Serverless/"},{"name":"API Gateway","slug":"API-Gateway","link":"/tags/API-Gateway/"},{"name":"Lambda","slug":"Lambda","link":"/tags/Lambda/"},{"name":"Restful api","slug":"Restful-api","link":"/tags/Restful-api/"},{"name":"CS","slug":"CS","link":"/tags/CS/"},{"name":"트랜잭션","slug":"트랜잭션","link":"/tags/%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98/"},{"name":"Database","slug":"Database","link":"/tags/Database/"},{"name":"DB","slug":"DB","link":"/tags/DB/"},{"name":"JDBC","slug":"JDBC","link":"/tags/JDBC/"},{"name":"Timeout","slug":"Timeout","link":"/tags/Timeout/"},{"name":"STIS","slug":"STIS","link":"/tags/STIS/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"POJO","slug":"POJO","link":"/tags/POJO/"},{"name":"EJB","slug":"EJB","link":"/tags/EJB/"},{"name":"REful API","slug":"REful-API","link":"/tags/REful-API/"},{"name":"REST","slug":"REST","link":"/tags/REST/"},{"name":"Batch","slug":"Batch","link":"/tags/Batch/"},{"name":"Spring Batch","slug":"Spring-Batch","link":"/tags/Spring-Batch/"},{"name":"DI","slug":"DI","link":"/tags/DI/"},{"name":"의존성주입","slug":"의존성주입","link":"/tags/%EC%9D%98%EC%A1%B4%EC%84%B1%EC%A3%BC%EC%9E%85/"},{"name":"IoC","slug":"IoC","link":"/tags/IoC/"},{"name":"제어의역전","slug":"제어의역전","link":"/tags/%EC%A0%9C%EC%96%B4%EC%9D%98%EC%97%AD%EC%A0%84/"},{"name":"MVC","slug":"MVC","link":"/tags/MVC/"},{"name":"MVC2","slug":"MVC2","link":"/tags/MVC2/"},{"name":"Spring MVC","slug":"Spring-MVC","link":"/tags/Spring-MVC/"},{"name":"SOLID","slug":"SOLID","link":"/tags/SOLID/"},{"name":"객체지향 5원칙","slug":"객체지향-5원칙","link":"/tags/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-5%EC%9B%90%EC%B9%99/"},{"name":"객체지향","slug":"객체지향","link":"/tags/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5/"},{"name":"모니터링 시스템","slug":"모니터링-시스템","link":"/tags/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EC%8B%9C%EC%8A%A4%ED%85%9C/"},{"name":"Prometheus","slug":"Prometheus","link":"/tags/Prometheus/"},{"name":"Grafana","slug":"Grafana","link":"/tags/Grafana/"},{"name":"Expoter","slug":"Expoter","link":"/tags/Expoter/"},{"name":"AWS lambda","slug":"AWS-lambda","link":"/tags/AWS-lambda/"},{"name":"nodejs","slug":"nodejs","link":"/tags/nodejs/"},{"name":"Kinesis","slug":"Kinesis","link":"/tags/Kinesis/"},{"name":"중복레코드 처리","slug":"중복레코드-처리","link":"/tags/%EC%A4%91%EB%B3%B5%EB%A0%88%EC%BD%94%EB%93%9C-%EC%B2%98%EB%A6%AC/"},{"name":"Netty","slug":"Netty","link":"/tags/Netty/"},{"name":"Timer","slug":"Timer","link":"/tags/Timer/"},{"name":"Wheel Timer","slug":"Wheel-Timer","link":"/tags/Wheel-Timer/"},{"name":"Hashed Wheel Timer","slug":"Hashed-Wheel-Timer","link":"/tags/Hashed-Wheel-Timer/"},{"name":"RDS","slug":"RDS","link":"/tags/RDS/"},{"name":"Oracle","slug":"Oracle","link":"/tags/Oracle/"},{"name":"업그레이드","slug":"업그레이드","link":"/tags/%EC%97%85%EA%B7%B8%EB%A0%88%EC%9D%B4%EB%93%9C/"}],"categories":[{"name":"AWS","slug":"AWS","link":"/categories/AWS/"},{"name":"CS","slug":"CS","link":"/categories/CS/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Lambda","slug":"AWS/Lambda","link":"/categories/AWS/Lambda/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"DB 트랜잭션","slug":"CS/DB-트랜잭션","link":"/categories/CS/DB-%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98/"},{"name":"JDBC","slug":"Java/JDBC","link":"/categories/Java/JDBC/"},{"name":"POJO","slug":"Spring/POJO","link":"/categories/Spring/POJO/"},{"name":"RESTful API","slug":"CS/RESTful-API","link":"/categories/CS/RESTful-API/"},{"name":"Spring Batch","slug":"Spring/Spring-Batch","link":"/categories/Spring/Spring-Batch/"},{"name":"Spring DI &amp; IoC","slug":"Spring/Spring-DI-IoC","link":"/categories/Spring/Spring-DI-IoC/"},{"name":"Spring MVC","slug":"Spring/Spring-MVC","link":"/categories/Spring/Spring-MVC/"},{"name":"객체지향 5원칙(SOLID)","slug":"CS/객체지향-5원칙-SOLID","link":"/categories/CS/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-5%EC%9B%90%EC%B9%99-SOLID/"},{"name":"모니터링","slug":"모니터링","link":"/categories/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81/"},{"name":"Kinesis","slug":"AWS/Kinesis","link":"/categories/AWS/Kinesis/"},{"name":"Spring Framework","slug":"Spring/Spring-Framework","link":"/categories/Spring/Spring-Framework/"},{"name":"Prometheus&#x2F;Grafana","slug":"모니터링/Prometheus-Grafana","link":"/categories/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81/Prometheus-Grafana/"},{"name":"Netty","slug":"Netty","link":"/categories/Netty/"},{"name":"Timer","slug":"Netty/Timer","link":"/categories/Netty/Timer/"},{"name":"RDS","slug":"AWS/RDS","link":"/categories/AWS/RDS/"}]}