{"pages":[],"posts":[{"title":"kinesis 중복레코드 처리(atleast once)","text":"Kiensis란?Kinesis는 실시간으로 데이터 스트림을 수집, 처리, 분석해주는 AWS 서비스이다. 데이터 스트림 수집 및 저장 샤드의 수를 조절하여 스트림을 얼마나 받을지 조절할 수 있음 데이터 중복이 일어나는 이유애플리케이션에 레코드가 두 번 이상 전달되는 주된 이s유는 두가지로 나눌 수 있다. 생산자 재시도 소비자 재시도 각각의 경우에 어떤 이유로 일어나는지 알아보자 생산자 재시도생산자재시도가 일어나는 가장 큰 이유는 네트워크 이슈문제일 가능성이 크다Kiensis 스트림에서 승인을 받기 전에 네트워크 관련 시간초과가 발생한다면 생산자는 레코드가 스트림에 전달되었는지 알 수 없다이러한 경우 동일한 데이터에 대해 PutRecord를 2번 이상 호출 할 수있다.(최대 3번까지 호출가능)중복을 철저히 방지해야하는 애플리케이션은 처리할 때 레코드에 기본키를 포함시켜서 처리해줘야 한다. 소비자 재시도사실 생산자 재시도보다는 소비자 재시도가 훨씬 더 많이 발생한다다음과 같은 경우에 동일한 샤읃의 레코드 프로세서가 중복실행된다 작업자가 예기치 않게 종료된 경우 작업자 인스턴스가 추가 또는 제거된 경우 샤드가 병합 또는 분할된 경우 애플리케이션이 배포된 경우 설명이 모호할 수 있으니 구체적인 예를 통해 흐름을 살펴보자샤드 1개와 샤드를 처리하는 작업자 1개가 있다고 가정해보자마지막 체크포인트가 레코드 번호 10000에 있다는 가정하에 다음의 이벤트 흐름을 살펴보자 작업자가 샤드에서 다음 레코드 배치(레코트 10001부터 20000까지)를 읽습니다 그런 다음 작업자가 레코드 배치를 연결된 레코드 프로세서로 전달합니다 레코드 프로세서가 데이터를 집계하고 Amazon S3 파일을 생성하며 파일을 Amazon S3로 업로드합니다. 새로운 체크포인트가 발생하기 전에 작업자가 예기치 않게 종료됩니다 애플리케이션, 작업자 및 레코드 프로세서가 다시 시작됩니다 이제 작업자가 마지막으로 성공한 체크포인트(여기서는 10001)에서 읽기 시작합니다 따라서 레코드 10001 ~ 20000이 두번 이상 소비됩니다 운영 시스템 해결방법위와 같은 이유로 중복레코드에 대한 상황이 발생할 수 있음을 인지하고 현재 운영중인 시스템에서는 이에대한 해결방법을 세웠다실제로 운영중인 시스템에서 각 레코드의 항목들에는 그 항목을 유일하게 결정지을 수 있는 key값이 들어가있다결국 해당 data insert문에 대하여 merge into 문법을 사용하여 중복되지않게 적재되도록 처리하였다","link":"/2022/03/25/kinesis-%EC%A4%91%EB%B3%B5%EB%A0%88%EC%BD%94%EB%93%9C-%EC%B2%98%EB%A6%AC-atleast-once/"},{"title":"RESTful API","text":"현대 애플리케이션은 대부분 프론트엔드라 부르는 클라이언트와 백엔드라 부르는 서버가 상호간 데이터를 주고받는 형태의 아키텍처를 가지고 있다. 이러한 구조의 가장 큰 특징중 하나는 서버와 클라이언트가 독립적으로 진화할 수 있다는 것이다.독립적으로 진화한다는 뜻은 각각의 업데이트 내용이 서로에게 영향을 미치지 않는 다는 것이다. 대표적인 예는 웹(web)이다. 웹 페이지의 변경이 브라우저에 영향을 미치지 못하고, 브라우저의 변경또한 페이지에 영향을 미치지 못한다. 서버와 클라이언트가 서로에게 영향을 끼치지 않고 독립적으로 진화하기 때문이다. 이러한 클라이언트 서버간의 독립적 진화를 위한 분산시스템 아키텍처로 가장 널리 쓰이는게 REST (Representatioin State Transfer) 아키텍쳐이다 REST(Representation State Transfer)REST는 2000년 HTTP의 주요 저자중 한 사람인 로이 필딩에 의해 제안되었다.그는 웹의 장점을 최대한 활용할 수 있는 아키텍처로써 REST를 발표하였고, 이를 통해 웹기술이 지속적으로 발전할 수 있게 되었다. 많은 사람들이 REST가 URI 패턴과 GET,POST 등의 HTTP Method 의 조합으로 이루어져 있다고 생각하지만,REST 아키텍처는 아키텍처라는 그 이름답게 결국 제약조건들의 집합이다. REST는 다음 여섯가지 제약조건을 가지고 있다. Client-Server Stateless Cache Uniform Interface Layered System Code On Demand(Optional) 각각에 대하여 살펴보도록 하자 Client-Server흔히들 이야기하는 서버와 클라이언트의 관계를 의미한다. 대부분 현대 애플리케이션은 서버-클라이언트 기반으로 만들어지고 사실상 이 구조를 벗어나는 것 자체가 힘든일이기 때문에 자연스럽게 만족되는 제약조건이라 할 수 있다. Stateless서버는 클라이언트의 각각의 요청을 모두 별개의 것으로 인식해야하고 이를 위해 모든 요청은 각자가 필요한 정보를 모두 담고 있어야 한다.요청 하나만 봐도 그 요청의 내용을 바로 알아볼 수 있어야 한다는 것이다. CacheHTTP라는 존재하는 프로토콜을 사용하기 때문에 웹에서 사용되는 기술인 캐시 역시 사용 가능하다.모든 서버응답은 캐시의 사용가능여부를 알고있어야하여, 캐시 사용을 고려한 설계가 필요하다. Uniform Interface구성요소들(서버,클라이언트)간의 인터페시으가 균일애햐 한다는 의미이다. 구체적으로 미디어 유형이나, 리소스 식별자 등을 구별하는 문법이 상호간 동일해야 한다는 뜻이다.이를 위해 REST는 네가지 제약사항을 제시하고 있다. identification of resources리소스를 식별하는 방법이 동일해야 한다. 흔히들 URI를 통해 리소스를 식별한다 manipulation of resources through representation리소스 자체를 전송하는 것이 아닌 리소스의 표현을 전송한다는 뜻. 서버에 있는 리소스가 아니라 현재 리소스의 상태를 반영하는 표현체를 전송함으로써 서버의 리소스 상태가 변해도 클라이언트에는 영향을 끼치지 못한다. self-descriptive messages요청이나 응답에는 스스로를 설명하는 정보를 포함하고 있어야 한다. 따라서 수신자는 이 정보를 통해 메시지를 이해할 수 있다. hypermedia as the engine of application state애플리케이션의 상태는 하이퍼미디어에 의해 변경된다는 것이다. 따라서 서버는 하이퍼미디어를 통해 다음 액션에 대한 선택지를 클라이언트에게 제공해야 한다. Layered System클라이언트 혹은 서버 모두 미들웨어 구성을 추가할 수 있는 구조를 가지고 있어야 한다는 의미이다. Code On Demand(Optional)서버는 클라이언트로 실행 가능한 프로그램을 전달할 수 있어야 한다. 쉽게 Javascript를 생각하면 된다. 그러나 이 조건은 선택사항이며 필수적이지는 않다. RESTful APIRESTful API(REST API)란 위의 제약조건에 따르는 애플리케이션 프로그래밍 인터페이스를 뜻한다. 그러나 우리가 RESTful API라고 부르는 것들은 사실 REST하지 않은 경우가 대부분이다. 특히, self-descriptve messages와 hypermedia as the engine of application state 원칙을 지키는 것이 상당히 까다로운 편이기 때문에 이 두원칙을 지키지 못하는 경우가 많다. 물론 로이 필딩은 이런 API를 REST라 불러선 안된다고 주장하지만 이미 많은 개발자들과 기업들은 REST 원칙을 지키지 못한 API들을 RESTful API라고 부르고 있다. 개인적인 생각원칙적인 REST 아키텍처 스타일을 알고있는 많은 사람들이 현대에 많은 글들과 회사에서 단지 몇가지 URL 규칙과 HTTP 메소드가 필요했을 뿐인 많은 사람들이 REST란 용어를 납치했다고까지 표현한다. 사실 개인적으론 이러한 논쟁이 머리아프게만 느껴지고 무슨 의미가 있나 싶기는 하지만, 이런 논쟁들이 좀 더 견고하고 표준화된 RESTful API 개념을 정립하는데 도움이 되겠거니 생각한다. 이런한 논쟁을 뒤로 하고 나는 결국 나만의 RESTful API를 정의 내렸다. Restful API란 HTTP URI(Uniform Resource Identifier)를 통해 자원(Resource)를 명시하고, HTTP Method(POST,GET,PUT,DELETE)를 통해 해당 자원에 대한 CRUD Opertaion을 적용한것.논란이 끝나면 새로운 정의가 나올 수 있겠지만 일단은 이렇게 알고있는게 마음편하다.","link":"/2022/03/26/RESTful-API/"},{"title":"객체지향 5원칙(SOLID)","text":"2000년대 초 로버트 마틴이 명명한 객체 지향 프로그래밍의 다섯가비 기본원칙을 마이클 페더스가 원칙의 앞글자를 따서 다시 SOLID라고 소개하였다.SOLID의 5대원칙은 다음과 같다. 단일 책임 원칙(Single Responsibility Principle) 개방 폐쇄 원칙(Open/Cloed Principle) 리스코프 치환 원칙(Liskov Subsitution Principle) 인터페이스 분리 원칙(Interface Segregation Principle) 의존관계 역전 원칙(Dependency Inversion Principle) 이 다섯가지 원칙애 대해 자세히 알아보도록 하자 단일 책임 원칙 : SRP(Single Responsibility Principle)모든 클래스는 하나의 책임만 가지며, 클래스는 그 책임을 완전히 캡슐화 해야함을 일컫는다.다시말해 클래스가 제공하는 모든 서비스는 단 하나의 책임을 수행하는데 집중되어야 한다는 뜻이다. SRP를 지키지 못하는 경우1234567891011121314public class 강아지 { final static Boolean 수컷 = true; final static Boolean 암컷 = false; Boolean 성별; void 소변보다() { if (this.성별 == 수컷) { // 한쪽 다리를 들고 소변을 보다. } else { // 뒷다리 두 개를 굽혀 앉은 자세로 소변을 본다. } }} 메소드에서 수컷, 암컷의 경우를 모두 구현하려고 하여 단일 책임 원칙을 위반하고 있는것을 볼 수 있다. SRP를 지키는 경우123456789101112131415abstract class 강아지 { abstract void 소변보다();}class 수컷강아지 extends 강아지 { void 소변보다() { // 한쪽 다리를 들고 소변을 본다. }}class 암컷강아지 extends 강아지 { void 소변보다() { // 뒷다리 두 개로 앉은 자세로 소변을 본다. }} 그래서 위와 같이 추상클래스를 두고 각각의 클래스가 자신의 특징에 맞게 메소드를 구현해서 사용하는것으로 리팩토링 할 수 있다. 개방 폐쇄의 원칙 : OCP(Open Closed Principle)개방-폐쇄 원칙은 소프트웨어 개체(클래스, 모듈, 함수 등)는 확장에 대해 열려 있어야 하고, 수정에 대해서는 닫혀 있어야 한다는 프로그래밍 원칙이다. 다시 말하면 요구사항의 변경이나 추가사항이 발생하더라도, 기존 구성요소는 수정이 일어나지 말아야 하며 쉽게 확장이 가능하여 재사용할 수 있어야 한다는 뜻이다.로버트 마틴은 OCP는 관리가 용이하고 재사용 가능한 코드를 만드는 기반이며, OCP를 가능케 하는 중요한 메커니즘은 추상화와 다형성이라고 설명한다. 비밀번호 암호화를 강화해야한다는 요구사항이 새롭게 들어왔다고 가정하자. 비밀번호 암호화를 강화하기 위해 다음과 같이 SHA-256알고리즘을 사용하는 새로운 PasswordEncoder를 생성하였다. 1234567public class SHA256PasswordEncoder{ public String encryptPassword(final String pw){ // SHA-256 암호화 메소드 }} 그리고 새로운 비밀번호 암호화 정책을 적용하려고 봤더니 UserService를 다음과 같이 수정해주어야 한다는 것이 발견되었다. 1234567public class UserService{ private final SHA256PasswordEncoder passwordEncoder; ...} 해당 코드의 문제가 보이는가?위 코드는 나중에 비밀번호 암호화 정책을 변경해야 한다는 요구사항이 온다면 또 다시 UserService에 변경이 필요해진다. 이는 기존의 코드를 수정하지 않아야 하는 개방 폐쇄 원칙에 위배된다.결국 이러한 문제를 해결하고 개방 폐쇄 원칙을 지키기 위해서는 추상화에 의존해야 한다. 12345678910111213141516171819202122public interface PasswordEncoder { String encryptPassword(final String pw); }public class SHA256PasswordEncoder implements PasswordEncoder { @Override public String encryptPaswword(final String pw){ ... }}public class UserService{ private final PasswordEncoder passwordEncoder; public void adduser(final String email, final String pw){ final String encryptedPassword = passwordEncoder.encryptPassword(pw); ... }} 개방 폐쇄 원칙이 본질적으로 얘기하고자 하는것은 결국 추상화이다. 이는 런타임 의존성과 컴파일 의존성이 객체 지향 프로그래밍에서는 동일하지 않다는 것을 의미한다. 리스코프 치환 원칙 : LSP(Liskov Substitution Principle)리스코프 치환 원칙은 1988년 바바라 리스코프가 올바른 상속 관계의 특징을 정의하기 위해 발표한 내용으로, 하위 클래스는 상위클래스의 모든 기능들을 수행 할 수 있어야함을 의미한다.즉 상위클래스을 사용하는 객체는 그 객체가 하위클래스로 변경되어도 문제없이 수행되어야 한다. 정말 당연한 원칙이지만 실무에서 좀처럼 지켜지지 않는 원칙중에 하나이다. 대부분의 경우 상위클래스의 메소드를 override하면서 문제가 발생하게 된다. 상위클래스의 기존 메소드를 하위클래스에서 잘못 수정하게 되면서 문제가 생기게 되는것이다. LSP를 잘 지키기 위해서는 override를 안하면 되는것이지만, 이는 절대적인 방법이 아니다.결국 상속을 할 떄 override가 필요하다면 상위클래스의 기능을 충실히 수행하고 기능의 추가만 신중하게 수행하면 된다. LSP는 결국 현재 하위클래스가 상위클래스의 기존 메소드의 의미를 해지지 않는지 신중히 고민을 하고 올바르게 상속하라는 의미이다. 인터페이스 분리의 원칙 : ISP(Interface Segregation Principle)인터페이스 분리 원칙은 클라이언트가 자신이 이용하지 않는 메서드에 의존하지 않아야 한다는 원칙이다. 다시 말하면 자신이 사용하지 않는 인터페이스는 구현하지 말아야 한다는 원칙이다. 하나의 큰 인터페이스를 상속받기보다는 인터페이스를 구체적이고 작은 단위들로 분리시켜 꼭 필요한 인터페이스만 구현하다는 의미이다. SRP가 클래스의 단일책임을 강조했다면 ISP는 인터페이스의 단일책임을 강조한다. 의존 역전 원칙 : DIP(Dependency Inversion Principle)의존 역전의 원칙은 다음과 같은 내용을 담고 있다. 상위 모듈은 하위 모듈에 의존해서는 안된다. 상위 모듈과 하위 모듈 모두 추상화에 의존해야한다. 추상화는 세부 사항에 의존해서는 안된다. 세부사항이 추상화에 의존해야한다. 의존 역전 원칙은 클래스 사이에는 의존관계가 존재하기 마련이지만, 구체적인 클래스에 의존하지말고 추상화에 의존하는 설계를 의미한다. 우리는 위의 예시들을 살펴보면서 의존 역전 원칙에 준수하도록 코드를 수정한 경험이 있다. 바로 OCP를 설명하기 위해 살펴봤던 SimplePasswordEncoder 예제가 DIP에 부합하는 리팩토링 과정이다. 예시에서 살펴보았든 의존 역전 원칙(DIP)는 개방 폐쇄 원칙(OCP)와 밀접한 관련이 있으며, 의존 역전 원칙이 위배되면 개방 폐쇄 원칙 역시 위배되게 될 가능성이 높다.","link":"/2022/03/26/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-5%EC%9B%90%EC%B9%99-SOLID/"},{"title":"DB 트랜잭션","text":"트랜잭션이란?트랜잭션은 하나의 작업을 수행하기 위해 필요한 데이터베이스의 연산들을 모아놓은 것으로, 데이터베이서에서 논리적인 작업의 단위이며 장애가 발생했을 때 데이터를 복구하는 작업의 단위이다. 현업에서 쓰이는 개념으로 쉽게 설명하면 트랜잭션 단위로 데이터의 커밋과 롤백이 이루어진다. 커밋(Commit) : 모든 부분작업이 정상적으로 완료되면 이 변경사항을 한꺼번에 DB에 반영한다. 롤백(Rollback) : 부분 작업이 실패하면 트랜잭션 실행 전으로 되돌린다.이때, 모든 연산을 취소하지 않고 정해진 부분까지만 되돌리고 싶을 때 사용하는 것이 savepoint이다. 트랜잭션의 특징(ACID)트랜잭션이 성공적으로 처리되어 데이터베이스의 무결성과 일관성을 보장하기 위해 4가지 특징을 만족해야한다. 4가지 특징은 다음과 같다. 원자성(Atomicity) 일관성(Consistency) 격리성(Isolation) 지속성(Durability) 각각의 특징에 대하여 자세하게 알아보자 원자성 (Atomicity) 트랜잭션을 구성하는 연산들은 모두 정상적으로 실행되거나 하나도 실행되지 않아야 한다는 all or nothing 방식이다. 트랜잭션의 연산은 데이터베이스에 모두 반영되든지 아니면 전혀 반영되지 않아야한다. 트랜잭션 내의 모든 명령은 반드시 완벽하게 수행되어야 하며, 모두가 완벽히 수행되지 않고 어느 하나라도 오류가 발생한다면 트랜잭션 전부가 취소되어야 한다. 일관성 (Consistency) 트랜잭션이 실행을 성공적으로 완료하면 언제나 일관성 있는 데이터베이스 상태로 유지하는 것을 의미한다. 예를 들어 무결성 제약이 모든 계좌는 잔고가 있어야 한다면 이를 위반하는 트랜잭션은 중단된다. 독립성 (Isolation) 트랜잭션 수행시 다른 트랜잭션의 연산 작업이 끼어들지 못하도록 보장하는 것을 의미한다. 수행중인 트랜잭션은 완전히 완료될 때까지 다른 트랜잭션에서 수행 결과를 참조할 수 없다. 예를 들어 은행 관리자는 이체 작업을 하는 도중 쿼리를 실행하더라도 특정 계좌간 이체하는 양 쪽을 볼 수없다. 성능 관련 이유로 인해 이 특성은 가장 유연성이 있는 제약조건이다. 지속성 (Durability) 성공적으로 수행된 트랜잭션은 영구적으로 반영되어야 함을 의미한다. 트랜잭션 연산보통 DB를 사용 할 때, 쿼리를 날리는 시점에 데이터베이스에 반영된다고 생각한다. 하지만 데이터베이스에 반영되는 시점은 트랜잭션 연산이 성공적으로 완료되는 시점에 실제 데이터베이스에 반영이 된다. 트랜잭션 연산에는 크게 두가지 과정이 있다. commit 연산 트랜잭션이 성공적으로 수행되었음을 선언(작업 완료) commit 연산이 실행 된 후에야 트랜잭션의 수행결과가 데이터베이스에 반영되어 일관된 상태를 지속적으로 유지. commit 연산의 실행을 통해 트랜잭션의 수행이 성공적으로 완료되었음을 선언하고 결과를 최종 데이터베이스에 반영. rollback 연산 트랜잭션이 수행을 실패했음을 선언(작업 취소) rollback 연산이 실행되면 트랜잭션이 지금까지 실행한 연산의 결과가 취소되고 트랜잭션이 수행되기 전의 상태로 돌아간다. 트랜잭션 수행 도중 일부 연산이 처리되지 못한 상황에서는 rollback 연산을 실행하여 트랜잭션의 수행이 실패했음을 선언하고, 모순되지 않도록 데이터베이스를 트랜잭션 수행 전의 일관된 상태로 되돌려야한다. 트랜잭션 상태트랜잭션은 위와 같은 연산을 수행할 떄 크게 5가지의 상태가 존재하고 상태 처리 과정은 아래 그림과 같다 활성(Active) : 트랜잭션이 정상적으로 실행중인 상태실패(Failed) : 트랜잭션 실행에 오류가 발생하여 중단된 상태철회(Aborted) : 트랜잭션이 비정상적으로 종료되어 Rollback 연산을 수행한 상태부분 완료(Partially Committed) : 트랜잭션의 마지막 연산까지 실행했지만, Commit 연산이 실행되기 직전의 상태완료(Committed) : 트랜잭션이 성공적으로 종료되어 Commit 연산을 실행한 후의 상태","link":"/2022/03/26/DB-%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98/"},{"title":"모니터링 시스템(Prometheus, Grafana)(1)","text":"2018년 유지보수중이던 시스템이 기존 NT 서버에서 AWS로 모든 인프라를 옮기는 대공사를 진행하게 되었다.인프라 전면전환 작업은 2년 가까운 시간이 되어서야 반영이 되었고, 2020년경부터 새로운 AWS인프라 위의 시스템을 유지보수하기 시작했다. 각종 문제들이 많이 생기기 시작했지만 가장 시급한 문제는 모니터링 시스템의 부재였다. 현재 내가 운영하고 있는 시스템은 실시간 대용량 트랜잭션을 처리하는 시스템으로, 장애발생시 5분 이내에 복구조치가 되도록 계약되어 있었고, 이를 위해서 모니터링 체계 구축은 필수적인 작업이었다. 많은 조사가 있었고 결국 우리는 프로메테우스와 그라파나라는 오픈소스를 사용하여 모니터링 체계를 구축하기 시작했다. 왜 프로메테우스인가?회사생활을 하다보면, 아니 개발자로서 살아가다보면 기술을 이유없이 의미없이 가져다 쓰는 경우가 굉장히 많다. 얼마전 지인으로부터 모니터링 시스템에 관해 이야기하다 프로메테우스를 선택한 이유에 대한 질문을 받게되었다. 답변을 하기 위해 횡설수설 프로메테우스의 장점에 대해 이야기했지만, 막상 생각해보니 시스템을 구축할 당시 많은 고민을 해보고 선택하지는 않았음을 깨달았다. 물론 그 당시 나름의 이유가 있었지만 잘 기억이 안나기에 다시 한번 리마인드 하기 위해 관련 내용을 정리해보고자 한다. Prometheus 장점프로메테우스 Github에서 설명하고 있는 장점들은 다음과 같다. 다차원 데이터 모델 가능 다차원 데이터 모델을 활용할 수 있는 유연한 쿼리언어(PromQL) 분산 스토리지에서 어떠한 의존성도 없음 모든 데이터는 HTTP(REST) Pull 기반으로 가져온다. 물론 Push도 가능함 모니터링 타겟은 프로메테우스의 YAML 설정값을 통해 Discovery 많은 장점들이 있지만 결국 프로메테우스의 가장 큰 특징이자 장점은 Pull방식의 모니터링 오픈소스라는 점이다. Pull 방식이란 대상 애플리케이션의 Exporter Enpoint로부터 데이터를 scrape 해오는 방식을 말한다.이 방식 덕분에 모니터링 설정을 Data Backend에서 효율적으로 관리할 수 있고, 혹시라도 Prometheus 장애 발생시에도 애플리케이션에 지장이 가지 않을수가 있다.위와 같은 장점들이 결국 프로메테우스를 선택하게 된 가장 큰 이유가 되었다. 물론 프로메테우스가 장점만 존재하는것은 아니다. 이제부터는 프로메테우스의 한계점에 대해 알아보고자 한다. Prometheus 한계점 클러스터링 구조에 대한 미지원 프로메테우스는 좋은 모니터링 시스템이긴 하지만 결정적인 문제점들이 있다. 그 첫번째가 바로 클러스터링 구조에 대한 미지원 문제이다. 이는 확장성과 가용성에 문제를 가져오게 된다. 확장성시스템에서 모니터링 할 대상들이 많지 않다면 하나의 프로메테우스 서버로 감당이 가능하겠지만, 볼륨이 늘어난다면 버거워지기 마련이다. 이 문제를 해결하는 방법으로 Federation 이라는 방법을 사용한다. 프로메테우스 인스턴스를 여러개 기동한 다음, 중앙에 다른 프로메테우스로부터 메트릭을 수집하는 중앙 집중 프로메테우를 놓는 방식이고, 데이터 양에 대한 문제는 데이터 해상도를 줄이거나 평균, 합등의 대표값을 사용해서 해결 할 수 있다. 가용성프로메테우스는 하나의 서버로 기동되기 때문에 그 서버가 장애로 내려갈 경우, 그 시간동안은 매트릭을 수집할 수 없다는 단점을 가지고 있다. 이를 해결하기 위해서는 프로메테우스 인스턴스를 두개 이상 띄운 다음 같은 대상 시스템으로부터 매트릭을 수집하는 방식인데 이렇게 되면 해당 문제를 해결 할 수 있기는 하다. 위의 아키텍쳐들은 역시 클러스터링의 대용일 뿐 제대로 되어 보이지는 않는다. 이를 해결하기 위해 오픈소스 타노스가 나왔지만 이는 나중에 다뤄보도록 한다. 오래 된 값 저장 프로메테우스의 다른 문제점 중 하나는 로컬 디스크를 사용하기 때문에 일정 기간이 지나 오래된 데이터는 삭제가 된다는 점이다. 그래서 오래된 데이터에 대한 조회가 불가능하다. 물론 이 문제에 대한 해결책 또한 오픈소스 타노스를 이용한다면 어느정도 해결이 되겠지만 이는 다루는 내용을 벗어나므로 다루지 않겠다. 이러한 한계점들이 존재하지만 현재 운영시스템에서는 위와 같은 한계들을 인정하고서라도 프로메테우스의 장점을 높이 쳐줬기에 선택하게 되었다.현 시스템이 그렇게 크지 않기때문에 클러스터링 구조는 필요가 없을것이라 판단했고, 오래된 값 또한 아쉽긴 하지만 실시간 모니터링에 초점을 두다보니 크게 문제가 되지 않았다. 왜 Grafana인가?프로메테우스와 달리 그라파나는 초기 선택에 있어서 큰 고민이 필요하지 않았다. 많은 자료들을 찾아봐도 프로메테우스와 그라파나는 거의 짝궁처럼 붙어다니는 기술이었기 때문이다. 하지만 그라파나 또한 장단점이 있으니 이에 대해 알아보도록 하자. Grafana 장점공식 홈페이지를 통해서 말하고 있는 그라파나의 장점은 다음과 같다. 데이터베이스가 아닌 데이터 통합 Grafana에서는 데이터를 수집할 필요가 없다. 대신 기존 데이터들을 통합하여 시각화 하는 방식을 취합니다. 누구나 사용할 수 있는 대시보드 Grafana 대시보드는 다양한 소스에서 수집된 데이터를 다른 팀원과 공유하여 함께 데이터를 탐색할 수 있습니다. 누구나 동적 대시보드를 만들고 공유하여 협업과 투명성을 높일 수 있습니다. 누구나 볼 수 있는 데이터 Grafana는 단일 담당자가 아니라 조직의 모든 사람이 데이터에 엑세스 할 수 있어야 한다는 원칙에 따라 구축되었다. 데이터를 민주화함으로써 필요로 하는 사람들이 데이터를 쉽게 사용하고 액세스 할 수 있는 문화를 촉진하여 팀의 역량을 강화하는데 도움이 된다. 유연성 및 다용성 모든 데이터를 유연하고 다용도 대시보드로 변환한다. 고급 쿼리 및 변환 기능을 사용하여 패널을 사용자 정의하여 실제로 도움이 되는 시각화를 생성 할 수 있다. 위와 같은 장점들이 공식 홈페이지에서 설명하는 장점들이지만 사실 이러한 장점들은 다른 시각화 툴도 가지고 있는 장점들이다. 내가 생각하는 그라파나의 가장 큰 장점들은 다양한 데이터 소스와의 연동, 그리고 손쉬은 Alert 기능 추가라고 생각한다. 서론이 너무 길었고 이제부턴 프로메테우스 &amp; 그라파나의 설치 및 시스템 구축에 대해 다뤄보자","link":"/2022/03/28/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EC%8B%9C%EC%8A%A4%ED%85%9C-Prometheus-Grafana/"},{"title":"모니터링 시스템(Prometheus, Grafana)(2)","text":"프로메테우스와 그라파나의 전체적인 아키텍처 및 설치과정을 알아보도록 하자 프로메테우스/그라파나 아키텍쳐지난 게시물에서도 말했듯이 프로메테우스는 데이터소스, 그라파나는 시각화 툴의 역할을 각각 맡고 있다. 또한 프로메테우스는 서버 뿐만 아니라 다양한 노드(컴포넌트)가 수집한 데이터를 pull방식으로 가져오는 구조이다. 여기서 node는 프로메테우스에서 제공하는 서비스일 수도 있고 사용자가 직접 커스텀한 Exporter일수도 있다.그 구조는 아래와 같다. 프로메테우스를 구성하는 컴포넌트들은 다음과 같다 Prometheus Server데이터를 수집하고 저장하는 메인서버 Exportertarget metric 데이터 수집Http 엔드포인트를 설정하여 서버에서 메트릭을 수집하도록 지원HAProxy, StatsD, Graphite와 같은 서비스를 지원 AlertManager설정한 규칙에 따른 알림 처리(Grafana 자체적으로 알람시스템을 가지고 있어 사용하지 않았음) PushGatewayExporter를 이용하여 수집이 어려운 작업에 대한 매트릭 pushing 지원 Grafana시각화 툴 Client LibrariesJava, Scala, Go, Python, Ruby 등의 언어에 대한 프로메테우 연동 라이브러리 현재 운영중인 모니터링 시스템의 경우 대부분은 Exporter로 데이터를 가져오고 있고, 알람은 Grafana의 알람체계를 사용하고 있다. 결국 Exporter를 각 시스템에 맞게 잘 구현하는것이 모니터링 시스템 구축의 핵심이라 할 수 있다. 프로메테우스 설치압축파일 다운로드현재 우리 서버에 설치된 버전은 2.19.0 버전이다 $ wget https://github.com/prometheus/prometheus/releases/download/v2.19.0/prometheus-2.19.0.linux-amd64.tar.gz $ tar xvfz prometheus-2.19.0.linux-amd64.tar.gz$ cd prometheus-2.19.0.linux-amd64 파일을 받은 후 압축까지 해제하여줍니다. 압축 해제후 설치과정은 따로 필요없습니다. 바로 prometheus 바이너리 파일이 실행 프로그램입니다. 설정파일설치된 폴더안에 prometheus.yml라는 YAML파일이 있습니다. # my global configglobal:scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.# scrape_timeout is set to the global default (10s). # Alertmanager configurationalerting:alertmanagers: static_configs: targets:# - alertmanager:9093 # Load rules once and periodically evaluate them according to the global ‘evaluation_interval’.rule_files:# - “first_rules.yml”# - “second_rules.yml” # A scrape configuration containing exactly one endpoint to scrape:# Here it’s Prometheus itself.scrape_configs:# The job name is added as a label job=&lt;job_name&gt; to any timeseries scraped from this config. job_name: ‘prometheus’ # metrics_path defaults to ‘/metrics’# scheme defaults to ‘http’. static_configs: targets: [‘localhost:9090’] globalPrometheus의 전반적인 부분에 대한 설정 scrap_interval : 정보를 수집하는 주기를 설정 evalutaion_interval : 시계열을 만들고 알람을 발생시키는 주기를 설정 rule_filesPrometheus 에서 불러올 rules 파일에 대한 경로를 지정하는 설정 scrape_configsPrometheus에서 어떤 자원을 모니터링할지 설정기본값으로 ‘prometheus’이 지정되어있는데 Prometheus 프로그램에서 발생된 시계열데이터를 수집결국 이 설정값에 exporter를 연결시켜 데이터를 수집하므로 주된 설정값임 프로메테우스 실행실행시에는 설정파일을 지정해줘야 한다. $ ./prometheus –config.file=prometheus.yml 실행을 확인하귀 위해 브라우저를 열어 http://localhost:9090 으로 접속하면 프로메테우스 UI 화면이 나타난다. 또한 프로메테우스가 어떤 메트릭 정보들을 제공하는지 확인하고 싶다면 http://localhost:9090/metrics 경로에서 확인할 수 있다. 위의 정보들은 실제로 운영중인 시스템의 모니터링 metric 값들이다. 해당 값들을 프로메테우스에 제공하기 위한 node exporter에 관한 이야기를 해보자 Custom Node ExporterPrometheus에서 제공되는 오픈소스 프로그램중 Node Exporter라는 것이 있다. Node Exporter의 종류는 굉장히 다양하고 Oracle, Mysql 등 DB에서 쿼리만 제공하면 데이터를 추출해주는 Exporter도 존재한다. 관련 Exporter는 공식 프로메테우스 공식 홈페이지를 통해 링크가 제공되니 참고해보기 바란다. 하지만 우리 시스템에서는 좀 더 커스텀된 데이터 가공이 필요하였고 결국 커스텀 Exporter를 만들기로 결정하였다. 어짜피 방식은 HTTP(REST) 방식이면 되니 개발은 간단하였다. 우리가 선택한 기술은 aws lambda 였고 이를 위해 serverless framework를 사용하여 exporter를 개발하였다. Serverless Framework과 lambda에 대해서는 추후에 더 자세하게 다뤄보도록 하겠다.api 구현방식이 중요한것이 아니라 프로메테우스가 원하는 metric 포맷으로 데이터를 리턴해주는 api가 존재하기만 하면 된다. api를 개발하는 방식은 굉장히 여러가지이니 개발자 재량껏 편한 방식으로 개발하면 된다. Lambda 언어는 node js를 선택하였고 프로메테우스 metric 데이터 형식으로 변환하기위해 ‘prom-client’ 를 패키지 관리자를 통해 설치하여 간편하게 metric 데이터 포맷으로 변환하였다. 해당 소스는 다음과 같다 소스 일부분만 가져왔지만 내용을 보면 sql라는 설정파일에 쿼리를 작성하면 원하는 내용으로 metric 데이터로 변환하여 준다. 위으 소스에서는 데이터를 Guage 형태로 가져왔는데 프로메테우스의 Metric 데이터 타입은 4가지로 나눠진다. Counter Guague Histogram Summary 해당 타입별 정의와 쓰임새는 공식홈페이지를 참고하기 바란다.(https://prometheus.io/docs/instrumenting/exporters/) 어쨌든 이런식으로 개발된 api의 엔드포인트를 prometheus.yml에 설정하여주면 위에서 보여준것과 같이 metric 데이터가 수집된다. 이제는 해당 데이터를 Grafana를 통해 시각화 해주면 된다.이에 대한 내용은 다음 포스트에서 다뤄보기로 한다.","link":"/2022/03/29/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EC%8B%9C%EC%8A%A4%ED%85%9C-Prometheus-Grafana-2/"},{"title":"모니터링 시스템(Prometheus, Grafana)(3)","text":"앞서 말했듯이 Grafana는 시계열 데이터를 시각화하는데 가장 최적화된 대시보드를 제공해주는 오픈소스 툴킷이다. 주로 InfluxDB, Prometheus, Graphite등의 시계열 데이터베이스와 함께 사용되며 실시간 데이터분석, 모니터링등에서 많이 사용되고 있다. 특히 자체적인 Alert기능 제공은 해당 툴을 선택하는데 가장 큰 이유가 되었다. Grafana 설치Grafana를 설치과정은 공식사이트를 통해 자세하게 나와있다.(https://grafana.com/grafana/download) 공식문서에서 제공하는것처럼 설치과정을 따르고 나면 압축 해제된 폴더의 bin 디렉토리로 이동하여 grafana 서버를 실행시킬 수 있다. $ cd [압축 파일을 해제한 폴더]/bin$ ./grafana-server or grafana-server start 운영체제가 Redhat 계열이라면 아래 서비스 실행 명령어로 바로 실행시킬 수 있다. $ sudo service grafana-server start 실행 후 3000번 포트로 접근하면 아래와 같은 대시보드 화면이 나오게 된다. Grafana 웹 서버의 초기 username/password 는 admin/admin 이다. 로그인이 완료되면 비밀번호를 변경하를 페이지가 뜨는데 원치 않는다면 skip을 누르면 된다. 대시보드 구성그라파나 설치 후 모니터링 대시보드를 구성하기 위한 방법을 여러가지이지만, 꽤나 번거로운 작업이기에 외부 대시보드 포맷을 사용한다면 좀 더 쉽게 구성할 수 있다. 아래 사이트에서 각종 대시보드 포맷을 둘러보고 선택해서 사용하면 된다https://grafana.com/grafana/dashboards/ 위와같은 대시보드 포맷을 사용하지 않고 각자 데이터 소스를 선택하고, 데이터를 편집하여 고유 화면을 구성할 수도 있다. 현재 우리 시스템같은 경우는 Prometheus와 CloudWatch를 데이터소스로 사용하여 대시보드 화면을 구성하고 있다. 위와 같은 아키텍쳐를 기반으로 설계된 모니터링 대시보드는 다음과 같다 각자의 시스템에 맞는 대시보드를 꾸며 최적의 모니터링 화면을 설계해보도록 하자!","link":"/2022/03/29/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EC%8B%9C%EC%8A%A4%ED%85%9C-Prometheus-Grafana-3/"},{"title":"JDBC 타임아웃","text":"시스템을 운영하는 입장에서 개발을 진행한다면 다양한 상황들을 가정하게 된다. 프로그램이 갑작스럽게 죽었을 경우, 서버가 다운됐을 경우, DDos 공격을 당하게 되었을 경우등이 가정되는 상황들이다. 이러한 이벤트에서도 시스템은 피해를 최소화할 수 있어야 한다. 이와 관련하여 과거 진행되었던 개발건 중 JDBC 타임아웃 설정에 관한 좋은 경험이 있어 공유하고 설명하고자 한다. DB서버의 먹통2020년 실시간으로 들어오는 다량의 데이터들을 DB에 적재하는 프로그램 개발을 맡게 되었다. Kinesis로부터 읽어들인 데이터를 DB에 적재하면 되는 단순할 수 있는 개발건이었지만, 기존에 운영중인 시스템의 구조를 바꾸는 일이라 영향도가 꽤나 큰 건이었다. 기능 개발은 단기간에 끝났지만 성능테스트와 발생할 수 있는 다양한 상황에 대응하는 기능들을 추가하는데 공수가 더 들어가게 되었다. 다양한 상황중 하나를 소개하고 그 대응책으로 고른 내용을 공유하고자 한다. 그 상황은 다음과 같다. DB서버가 장애가 날 경우 프로그램은 어떻게 동작해야하는가? 의식의 흐름대로 개발을 한다면 다음과 같은 프로세스대로 동작하면 된다. DB가 죽을 경우 Kinesis로부터 Read하는 행위를 정지한다. DB Reconnect를 주기적으로 실시한다. DB Connect가 성공하는 순간 Kinesis로부터 Read행위를 재개한다. 이 프로세스에서 가장 핵심이 되는 문제는 1번, DB의 비정상적인 종료를 캐치하는 것이었다.DB Transaction 프레임워크로 Mybatis를 설정하였기에 statement 타임아웃 설정을 해주었고, 나머지 2,3번 프로세스대로 개발을 진행하였다. 개발 완료 후 DB를 중지시키는 테스트를 진행하였을 때 프로그램은 DB의 비정상적인 종료를 캐치하지 못하였다. DB의 응답을 기다리면서 Kinesis로부터 계속 데이터를 읽어들였고, 차오르는 메모리로 인해 oom이 발생하며 프로그램은 종료되었다.아래는 mybatis에서 설정해준 statement timeout 설정파일이다. …&lt;setting name=”defaultStatementTimeout” value=”25000”/&gt;… 무엇이 문제였을까? mybatis의 타임아웃 설정이 잘못되었던건가? 이를 이해하기 위해선 JDBC의 타임아웃 과정을 보면 이해할 수 있다.앞으로 나올 내용은 Naver O2에 포스팅 된 아주 좋은내용의 블로그를 참고하였다(https://d2.naver.com/helloworld/1321) JDBC typeJDBC는 자바 프로그램이 DBMS에 일관된 방식으로 접근할 수 있도록 API를 제공하는 자바 클래스들의 모임이다. 즉 데이터베이스에 연결 및 작업을 하기 위한 JAVA의 표준 인터페이스이다.JDBC의 유형은 총 4가지가 있는데 현재 재직중인 회사와 운영중인 시스템에선 주로 Type 4를 사용하고 있으므로 이에 대해서 다룬다.(추후에 JDBC에 대해서도 자세하게 다루도록 하겠다.)Type 4는 순수 자바로 이루어져 있으며 Java Socket으로 DB에 직접 교신하는 방식이다. 때문에 Socket Timeout값을 제대로 설정하지 않았을 경우 DB의 문제를 늦게 감지하고 장애로 이어질 수 있다. 위에서 설명한 상황이 바로 이런 상황에 해당된다. DBMS 통신 타임아웃 계층 위의 그림은 WAS와 DBMS의 통신시 타임아웃 계층을 단순화한 것이다. 여기서 Instance를 기본 Java Application으로 대체해도 문제가 없다. 그림에서 보이듯 상위레벨의 타임아웃은 하위레벨의 타임아웃에 의존성을 가지고 있다. Socket Timeout이 정상적으로 동작하지 않으면, 그보다 상위인 Statment Timeout과 Transaction Timeout도 정상적으로 동작하지 않는다. JDBC Socket Timeout의 default값은 OS의 Socket timeout에 영향을 받는다. 별도의 설정이 없을 경우 OS의 Default Socket Timeout값이 적용된다. 즉, 위의 상황에서 30분이 지난다면 Exception이 발생되었을 것이다. 하지만 실시간 프로그램에서 30분은 너무나 긴 시간이고 별도의 시간 설정이 필요해 보인다. 이제부터 각 타임아웃의 의미와 Mybatis에서 Socket Timeout 설정하는 방법에 대해 다뤄보자 Transaction TimeoutTransaction Timeout은 프레임워크나 애플리케이션 레벨에서 유효한 타임아웃이다. 간단히 말하면 전체 Statement를 수행하는데 걸리는 시간의 Timeout이라고 할 수 있다. 즉 StatementTimeout * N(Statement 수행수) 정도로 생각해볼 수 있다. Mybatis의 경우 Trasaction Timeout설정은 존재하지 않고 Statement Timeout설정만 존재한다. Statement TimeoutStatement 하나가 얼마나 오래 수행되어도 괜찮은지에 대한 한계값이다. Mybatis의 설정이 위의 예제에서 보여준 방법을 이용하면 된다. Socket Timeout위에서도 말했듯이 Type 4는 Socket을 이용한 DB통신 방식을 이용하고, 이는 DBMS가 Connection Timeout을 처리하지 않음을 의미한다. 즉, 애플리케이션과 DBMS 사이의 장애를 감지할 수 있는 방법은 Socket Timeout값을 설정하는 방법밖에 없다. 이를 간과하였기에 우리 시스템에서는 DB장애를 감지할 수 없었던 것이다. 단, Socket Timeout 값을 Statment의 수행시간을 제한하기 위해 사용하는것은 바람직하지 않으므로, Statement Timeout 값보다는 큰 값을 사용하기를 권장한다. Socket Timeout에는 두가지 옵션이 있고, 드라이버별로 설정방법이 다르다. Socket Connect 시 타임아웃(connectTimeout): Socket.connect(SocketAddress endpoint, int timeout) 메서드를 위한 제한 시간 Socket Read/Write의 타임아웃(socketTimeout): Socket.setSoTimeout(int timeout) 메서드를 위한 제한 시간 드라이버별 설정방법을 여기서 모두 다루지는 않고 Oracle의 경우 Mybatis에서 어떤식으로 설정해줬는지 내용을 공유하려 한다. …&lt;property name=”driver.oracle.jdbc.ReadTimeout” value=”10000”/&gt;&lt;property name=”driver.oracle.net.CONNECT_TIMEOUT” value=”10000”/&gt;… 위의 두 내용이 내가 Mybatis에 설정해준 Socket Timeout 값이다. 끝으로해당 내용을 공부하고 운영환경에 적용하면서 이 설정이 실제로 쓰일까에 대한 고민이 많이 있었다. 하지만 프로그램 반영 후 알 수없는 이유로 DB에 로그파일이 쌓이기 시작하며 스토리지가 모두 소비되었고, DB 서버가 죽는 상황이 실제로 발생하게 되었다. 해당 장애상황에서 대비되었던 설정으로 인해 모든 데이터를 유실 없이 복구할 수 있었다. 역시 운영환경에서 생각할 수 있는 모든 변수는 대비하는게 맞다는 경험을 한번 더 쌓게 되는 계기가 되었다.","link":"/2022/04/06/JDBC-%ED%83%80%EC%9E%84%EC%95%84%EC%9B%83/"},{"title":"Spring Batch","text":"Batch Program이란?일반적으로 배치(Batch) 프로그램이라 하면, 일련의 작업들을 하나의 작업단위로 묶어 연속적으로 일괄처리 하는 것을 말한다.예를 들어 하루전날의 집계된 요금데이터를 집계해야한다고 가정해보자. 이 업무는 하루에 1번만 수행하면 된다. 이를 위해 api를 구성하는것은 낭비가 된다. 또한 대량의 데이터를 처리하는 도중 실패가 된다면?? 이에 대한 처리를 어떻게 할 것인가? 이러한 단발성 대용량 데이터를 처리하는 프로그램을 배치프로그램이라 한다. 위에서 한 고민들을 살펴보면 단순히 집계하는 비즈니스 로직 이외에 고려해야할 부분이 많다는 것을 알 수 있다. 개발자가 비즈니스 로직 이외의 다른 부분들에 대한 고민을 덜어주도록 지원하는것을 프레임워크라 한다. 대표적인 프레임워크는 Spring이 있다. 그렇다면 Spring에서는 이런 배치프로그램을 지원하는 기능이 없을까? Spring 진영에서는 Spring Batch를 지원하며, 감히 말하건대 이 프레임워크가 Java개발자에게 있어서는 최선의 배치프레임워크라 자신한다. Spring Batch에 대해서는 아래에서 더 자세하게 다뤄보기로 하고 그 이전에 배치 프로그램이란 무엇인지 알고 넘어가도록 하자. 배치 프로그램이란 다음의 조건들을 만족하는 프로그램이다 대용량 데이터 - 대량의 데이터를 가져오거나, 전달하거나, 계산하는 등의 처리를 할 수 있어야 한다. 자동화 - 사용자의 개입 없이 실행되어야 한다. 견고성 - 잘못된 데이터를 충돌/중단 없이 처리할 수 있어야 한다. 신뢰성 - 무엇이 잘못되었는지 추적가능해야 한다(로깅, 알림) 성능 - 지정한 시간 안에 처리를 완료하거나 동시에 실행되는 다른 어플리케이션을 방해하지 않도록 수행되어야 한다. 자 이제는 이러한 배치프로그램의 개발을 지원하는 Spring Batch에 대해 더 자세하게 알아보자 Spring BatchSpring Batch는 2007년 Accenture와 SpringSource간의 협업으로 탄생하게 되었다. Accenture사의 배치업무에 대한 노하우와 SpringSouce의 기술력이 합쳐진 결과물이라고 할 수 있다. Spring Batch는 기본적으로 Spring의 특징 그대로를 사용할 수 있다. DI, AOP, 서비스 추상화 등의 스프링 프레임워크의 특징을 사용할 수 있으며, Accenture의 배치 아키텍쳐를 사용 할 수 있다는 의미이다. 여기에선 Spring Batch의 큰 줄기만 다뤄보도록 하겠다. 자세한 사용가이드는 공식 doc을 참고하면 된다.(https://docs.spring.io/spring-batch/docs/current/reference/html/) 위의 그림은 스프링 배치의 Job 구성에 관한 그림이다. 해당 그림에서 스프링의 큰 줄기개념들이 나오게 된다. 각각의 용어와 내용에 대해서 알아보도록 하자 JobSpring Batch에서 Job은 전체 배치 프로세스를 캡슐화하는 객체이다. 말이 어려울 수 있지만 쉽게 생각하면 결국 배치 프로그램을 이루는 업무단위의 최상위 계층이라고 생각하면 된다. Job은 사용자가 정의하기 나름이지만 최소한 1개의 Step으로는 이루어져 있으며, 복잡한 Job이 아닌 이상 2~10개의 Step을 권장한다. 배치 프로그램은 결국 여러개의 Job과 그 Job에 속해있는 여러개의 Step들로 이루어진다고 보면 된다. Step위에서 말했듯이 Step은 Job을 구성하는 요소이다. Step은 job의 독릭접으로 실행되는 순차적인 단계를 캡슐화한 도메인 객체이며, 실제 배치 처리를 정의하고 컨트롤하는 데 필요한 모든 정보를 가지고 있다.설명이 굉장히 모호하게 느껴질 수 있는데, 이는 Step의 모든 내용은 Job을 만드는 개발자의 재량이기 때문이다. 즉 개발자에 따라 Step은 간단할 수 도 있고 복잡할 수도 있다. 데이터베이스에서 데이터를 읽어서 파일을 쓰는 간단한 작업이 될 수도 있고, 프로세싱의 일부를 처리하는 복잡한 비즈니스 로직일 수도 있다. Step의 데이터 처리방법은 크게 두가지가 있다 Chunk지향 방식 Tasklet 방식 Spring Batch에서 추천하는 방식은 Chunk 지향방식이고 많은 사람들도 이 방식을 추천한다. 하지만 비즈니스로직이 Chunk 지향 방식으로 처리가 안되는 경우에는 Tasklet 방식을 사용할 수밖에 없다. Chunk 지향 방식 Spring Batch 구현체의 대부분은 ‘청크 지향’으로 개발되었다. 청크 지향 프로세싱이란 한 번에 데이터를 하나씩 읽어와서 트랜잭션 경계 내에서 쓰여질 ‘청크’를 만드는 것이다. 읽은 항목 수가 커밋 간격과 같아지면 ItemWriter가 청크 전체를 write하고, 트랜잭션이 컴ㅅ된다. 다음은 이 절차를 도식화한 그림이다. 다음 의사코드는 동일한 개념을 단순화된 형식으로 보여준다. 123456789List items = new Arraylist();for(int i = 0; i &lt; commitInterval; i++){ Object item = itemReader.read(); if (item != null) { items.add(item); }}itemWriter.write(items); Tasklet 방식 위에서 말했듯 청크 기반 처리로 구현할 수 없는 비즈니스 로직을 위해 Spring Batch는 TaskletStep을 제공한다. Tasklet은 excute 메소드 하나를 가진 심플한 인터페이스인데, 이 메소드는 RepeatStatue.FINISHED가 리턴되거나 실패했단 뜻으로 exception이 던져지기 전까지 TaskletStep을 반복적으로 호출한다. 각 Tasklet 호출은 트랜잭션으로 감싸져 있다. Tasklet을 실행하려면 빌더의 tasklet 메소드에 Tasklet 인터페이스를 구현한 빈을 넘겨야 한다. 1234567@Beanpublic Step step1() { return this.stepBuilderFactory.get(&quot;step1&quot;) .tasklet(myTasklet()) .build();} Quartz vs SpringBoot SchedulerSpring Batch의 큰 줄기는 위에서 다뤄봤다. 좀 더 자세한 설명과 예제가 필요하다면 공식 doc을 참고하길 바란다. 위의 내용을 읽었다면 배치 프로그램에서 중요한 부분이 빠졌다는 것을 알 수 있다. 바로 스케줄링 부분이다. 매일 또는 몇 시간 단위로 일정하게 프로그램을 실행시켜줄 스케줄러 기능이 Spring Batch에는 제공되지 않는다. 그래서 보통은 Quartz 라이브러리의 스케줄링 기능과 결합하여 많이들 사용하였다. 하지만 최근들어서는 SpringBoot에서 Scheudler 기능을 제공하기 시작했고, 이 기능과 묶어서 사용하는 케이스가 많아지게 되었다. 현재 내가 운영하는 시스템의 배치프로그램도 SpringBoot + Spring Batch 로 배치 프로그램이 동작하고 있다. 마치며서버개발자의 삶을 살아가다보면 배치프로그램의 개발은 피할 수 없는 일이 될 것이다. 위에서 소개한 Spring Batch는 그 개발 프레임워크로써 최고의 도구가 되기를 바란다.","link":"/2022/04/09/Spring-Batch/"},{"title":"Spring Framework란?","text":"Spring의 역사Spring Framework이 등장하기 전에는 EJB라는 기술을 통해 웹 애플리케이션을 개발하였다. 이 기술은 여러가지 복잡성으로 인해 사용하기 까다로웠고, 이러한 단점들을 보안하기 위한 기술들이 연구되었다. 그 과정에서 가장 호평을 받은 기술이 Spring Framework이다. 물론 Spring Framework가 처음부터 바로 나온것은 아니다. 2002년 로드 존슨은 자신이 출판한 저서(Expert One-on-One J2EE Design and Development)에 스프링의 핵심 개념과 기반 코드들을 소개하였다. 책 출간 직후 유겐 휠러와 얀 카로프가 로드 존슨에게 오픈 소스 프로젝트를 제안하였고, 전통적인 EJB라는 겨울을 넘어 새로운 시작이라는 뜻으로 Spring이라고 명칭을 짓게 되었다. Framework란?Spring은 항상 Fraemwork와 결합되어 Spring Framework라 불린다. 여기에서 사용된 Framework란 무엇일까?? Framework의 개념에 대해 설명할 떄 항상 Library와 비교되곤 한다. 두 개념이 유사한 점이 많아서일 것이다. 여기선 두 개념에 대한 공통점과 차이점에 대해 알아보고자 한다. Framework는 뼈대나 기반 구조를 뜻하고, 제어의 역전(IoC) 개념이 적용된 대표적인 기술이다. 소프트웨어에서의 프레임워크는 소프트웨어의 특정 문제를 해결하기 위해서 상호 협력하는 클래스와 인터페이스의 집합이라 할 수 있다.Library는 개발에 필요한 것들을 미리 구현해놓은 대상, 도구들의 집합을 말한다. 즉, 개발자가 만든 클래스에서 호출하여 사용하는 방식을 취하고 있다. Framework와 Library 모두 애플리케이션을 개발하는데 있어 쉽고 빠른 생산성을 위해 사용한다는 공통점을 가지고 있다. 이 둘의 가장 큰 차이는 바로 제어역전이다 관건은 애플리케이션의 흐름을 누가 쥐고 있느냐이다. Framework는 전체적인 흐름을 스스로 쥐고 있으면서 사용자는 그 안에서 필요한 코드를 짜 넣지만, Library는 사용자가 전체적인 흐름을 만들며 라이브러리를 가져다 쓴다. Spring FrameworkSpring Framework를 한 문장으로 표현한다면 ‘자바 엔터프라이즈 개발을 편하게 해주는 오픈 소스 경량급 애플리케이션 프레임워크’ 라고 할 수 있다. 즉, 애플리케이션 전 영역을 포괄하는 범용적인 프레임워크로써의 기능을 경량화하여(보다 쉽게 사용할 수 있게) 개발자에게 제공된흔 오픈소스 솔루션이라는 것이다. 이러한 스프링 프레임워크의 특징들을 하나씩 살펴보도록 하자. 경량 컨테이너경량 컨테이너로서 자바 객체를 직접 관리한다. 각각의 객체 생성, 소멸과 같은 라이프 사이클을 관리하며 스프링으로부터 필요한 객체를 얻어올 수 있다. POJO 기반의 구성POJO는 Plain Old Java Object의 약자로, 번역하면 평범한 오래된 자바 객체를 말한다. 마틴 파울러가 200년에 컨퍼런스 발표를 준비하다 만들어낸 용어인데, 중량 프레임워크들을 사용하게되면서 점점 무거운 객체를 만들게 된 것에 반발해서 사용되게 된 용어이다. 그 의미가 모호하고 와닿지 않을 수도 있다. 나 역시 의미가 잘 이해가 되지 않기에 추후에 POJO와 Spring에 대해 더욱 자세히 다뤄보도록 하겠다. 다만 토비의 스프링에서는 진정한 POJO란 객체지향적인 원리에 충실하면서, 환경과 기술에 종속되지 않고 필요에 따라 재활용 될 수 있는 방식으로 설계된 오브젝트라고 설명하였다. 이러한 Spring의 핵심적인 내용인 POJO에 대해서는 다음 포스팅에서 다뤄보도록 하겠다. IOC와 DI 지원컨트롤의 제어권이 사용자가 아니라 프레임워크에 있어서 필요에 따라 스프링에서 사용자의 코드를 호출한다. 이것을 제어의 역행(IoC)라고 한다.의존성 주입(DI)는 제어의 역행이 일어나는 것을 전제로 하여 스프링 내부의 객체들간의 관계를 만들어 줄 떄 사용된다. 말 그대로 특정 개체가 필요로 하는 객체를 외부에서 결정하여 연결시키는 것을 말한다. 이 또한 Spring의 핵심특징중 하나로 자세하게 다루기엔 길어지므로 다음 포스팅에서 다뤄보도록 하겠다. AOP 지원AOP(Asepect Oriented Programming)는 관점 지향 프로그래밍을 뜻한다. 대부분의 시스템에서 비즈니스 로직은 아니지만 보안, 로그, 트랜잭션과 같이 반드시 처리가 필요한 부분을 횡단 관리 심사라고 한다. 스프링에서는 이러한 관심사를 비즈니스 로직과 분리하여 중복된 코드를 줄이고 개발자가 비즈니스 로직에 집중하도록 만들어준다. 이 또한 방대한 내용이므로 따로 포스팅하도록 하겠다. WAS에 독립적인 개발환경과거의 EJB가 동작하려면 고가의 느리고 무거운 자바 서버(WAS)가 필요했다. 그에 반해 스프링은 가장 단순한 서버환경인 톰캣(Tomcat)이나 제티(Jetty)에서도 완벽하게 동작한다. 더군다나 Spring Boot에서는 자체 내장된 WAS를 사용하여 별도의 tomcat등을 설치할 필요도 없게 되었다. 이에관해 Spring Boot의 내장 WAS의 성능에 대해서 다뤄보는 포스팅을 추후세 작성하도록 하겠다. 마치며여기까지의 내용은 스프링의 맛만 보았다고 할 수 있다. 위에서 언급된 내용들을 좀 더 구체적이고 심화된 내용으로 다뤄보는 시간을 가지도록 하겠다.","link":"/2022/04/19/Spring-Framework%EB%9E%80/"}],"tags":[{"name":"AWS","slug":"AWS","link":"/tags/AWS/"},{"name":"Kinesis","slug":"Kinesis","link":"/tags/Kinesis/"},{"name":"중복레코드 처리","slug":"중복레코드-처리","link":"/tags/%EC%A4%91%EB%B3%B5%EB%A0%88%EC%BD%94%EB%93%9C-%EC%B2%98%EB%A6%AC/"},{"name":"REful API","slug":"REful-API","link":"/tags/REful-API/"},{"name":"REST","slug":"REST","link":"/tags/REST/"},{"name":"STIS","slug":"STIS","link":"/tags/STIS/"},{"name":"CS","slug":"CS","link":"/tags/CS/"},{"name":"SOLID","slug":"SOLID","link":"/tags/SOLID/"},{"name":"객체지향 5원칙","slug":"객체지향-5원칙","link":"/tags/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-5%EC%9B%90%EC%B9%99/"},{"name":"객체지향","slug":"객체지향","link":"/tags/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5/"},{"name":"트랜잭션","slug":"트랜잭션","link":"/tags/%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98/"},{"name":"Database","slug":"Database","link":"/tags/Database/"},{"name":"DB","slug":"DB","link":"/tags/DB/"},{"name":"모니터링 시스템","slug":"모니터링-시스템","link":"/tags/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EC%8B%9C%EC%8A%A4%ED%85%9C/"},{"name":"Prometheus","slug":"Prometheus","link":"/tags/Prometheus/"},{"name":"Grafana","slug":"Grafana","link":"/tags/Grafana/"},{"name":"Expoter","slug":"Expoter","link":"/tags/Expoter/"},{"name":"JDBC","slug":"JDBC","link":"/tags/JDBC/"},{"name":"Timeout","slug":"Timeout","link":"/tags/Timeout/"},{"name":"Sping","slug":"Sping","link":"/tags/Sping/"},{"name":"Batch","slug":"Batch","link":"/tags/Batch/"},{"name":"Spring Batch","slug":"Spring-Batch","link":"/tags/Spring-Batch/"}],"categories":[{"name":"CS","slug":"CS","link":"/categories/CS/"},{"name":"AWS","slug":"AWS","link":"/categories/AWS/"},{"name":"Kinesis","slug":"AWS/Kinesis","link":"/categories/AWS/Kinesis/"},{"name":"RESTful API","slug":"CS/RESTful-API","link":"/categories/CS/RESTful-API/"},{"name":"객체지향 5원칙(SOLID)","slug":"CS/객체지향-5원칙-SOLID","link":"/categories/CS/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-5%EC%9B%90%EC%B9%99-SOLID/"},{"name":"DB 트랜잭션","slug":"CS/DB-트랜잭션","link":"/categories/CS/DB-%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98/"},{"name":"모니터링","slug":"모니터링","link":"/categories/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81/"},{"name":"Prometheus&#x2F;Grafana","slug":"모니터링/Prometheus-Grafana","link":"/categories/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81/Prometheus-Grafana/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"JDBC","slug":"Java/JDBC","link":"/categories/Java/JDBC/"},{"name":"Spring","slug":"Spring","link":"/categories/Spring/"},{"name":"Spring Batch","slug":"Spring/Spring-Batch","link":"/categories/Spring/Spring-Batch/"},{"name":"Spring Framework","slug":"Spring/Spring-Framework","link":"/categories/Spring/Spring-Framework/"}]}